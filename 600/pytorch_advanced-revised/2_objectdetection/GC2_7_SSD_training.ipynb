{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "GC2-7_SSD_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2021/blob/main/600/pytorch_advanced-revised/2_objectdetection/GC2_7_SSD_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRDrOClOJvlA"
      },
      "source": [
        "# 2.7 学習と検証の実施\n",
        "\n",
        "- 本ファイルでは、SSDの学習と検証の実施を行います。手元のマシンで動作を確認後、AWSのGPUマシンで計算します。\n",
        "- p2.xlargeで約6時間かかります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQkSZ3f7JvlH"
      },
      "source": [
        "# 学習目標\n",
        "\n",
        "1.\tSSDの学習を実装できるようになる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRUqU4tnxmZl"
      },
      "source": [
        "---\n",
        "\n",
        "# Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVasAdJYxmZp"
      },
      "source": [
        "!echo \"Change to the JST notation.\"\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Japan /etc/localtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMAZ5ELyxmZp"
      },
      "source": [
        "!echo \"Start mounting your Google Drive.\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!echo \"Move to the working directory.\"\n",
        "%cd 202107_Tool-A/Work600/\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvNuqvC4xmZq"
      },
      "source": [
        "---\n",
        "# 共通準備\n",
        "\n",
        "\"pytorch_advanced\" folder should be ready before you come here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b2qZLfoxmZq"
      },
      "source": [
        "# Skip this if you have already issued git in advance. \n",
        "# If you come here by way of 600-PyTorchADL.ipynb, \n",
        "# you should skip the git command (as you have already issued in 600).  \n",
        "# If you run git when pytorch_advanced already exists, git tells the error and clone won't be made.\n",
        "\n",
        "#!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced\"):\n",
        "    print(\"OK. Alreadly git cloned. You can go.\")\n",
        "else:\n",
        "    print(\"You'd better go back to the first 600-PyTorchADL.ipynb\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGkLljtdxmZq"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcgSKlMxxmZr"
      },
      "source": [
        "%cd \"pytorch_advanced\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um0EwrGSxmZr"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqEb59O9xmZr"
      },
      "source": [
        "%cd \"2_objectdetection\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNqNiyHFxmZr"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-pUmMgPJvlI"
      },
      "source": [
        "---\n",
        "# 事前準備\n",
        "\n",
        "- **GCの**GPUインスタンスを使用します\n",
        "- フォルダ「utils」のssd_model.pyを利用します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wFXuAjsJvlI"
      },
      "source": [
        "# パッケージのimport\n",
        "import os.path as osp\n",
        "import random\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKIiLcdZJvlJ"
      },
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNcYx2L0JvlK"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rux859mS5dGO"
      },
      "source": [
        "---\n",
        "# VOC2012準備\n",
        "\n",
        "VOCdevkit/ from VOCtrainval_11-May-2012.tar is placed at /root .  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDDBrUtU54KX"
      },
      "source": [
        "# It takes one minutes or so.\n",
        "\n",
        "%cd /root\n",
        "!tar xf \"/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/2_objectdetection/data/VOCtrainval_11-May-2012.tar\"\n",
        "!ls /root/VOCdevkit\n",
        "%cd -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2hwPVpFJvlK"
      },
      "source": [
        "---\n",
        "# DatasetとDataLoaderを作成する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9scicyiOJvlL"
      },
      "source": [
        "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
        "\n",
        "\n",
        "# ファイルパスのリストを取得\n",
        "rootpath = \"/root/VOCdevkit/VOC2012/\"\n",
        "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
        "    rootpath)\n",
        "\n",
        "# Datasetを作成\n",
        "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "               'cow', 'diningtable', 'dog', 'horse',\n",
        "               'motorbike', 'person', 'pottedplant',\n",
        "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
        "input_size = 300  # 画像のinputサイズを300×300にする\n",
        "\n",
        "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
        "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
        "\n",
        "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
        "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
        "\n",
        "\n",
        "# DataLoaderを作成する\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
        "\n",
        "val_dataloader = data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbyl0KAwJvlL"
      },
      "source": [
        "# ネットワークモデルを作成する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dFZ6oVjJvlM"
      },
      "source": [
        "from utils.ssd_model import SSD\n",
        "\n",
        "# SSD300の設定\n",
        "ssd_cfg = {\n",
        "    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
        "    'input_size': 300,  # 画像の入力サイズ\n",
        "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
        "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
        "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
        "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
        "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
        "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
        "}\n",
        "\n",
        "# SSDネットワークモデル\n",
        "net = SSD(phase=\"train\", cfg=ssd_cfg)\n",
        "\n",
        "# SSDの初期の重みを設定\n",
        "# ssdのvgg部分に重みをロードする\n",
        "vgg_weights = torch.load('./weights/vgg16_reducedfc.pth')\n",
        "net.vgg.load_state_dict(vgg_weights)\n",
        "\n",
        "# ssdのその他のネットワークの重みはHeの初期値で初期化\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "        if m.bias is not None:  # バイアス項がある場合\n",
        "            nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "# Heの初期値を適用\n",
        "net.extras.apply(weights_init)\n",
        "net.loc.apply(weights_init)\n",
        "net.conf.apply(weights_init)\n",
        "\n",
        "# GPUが使えるかを確認\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードしました')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5tGwXegJvlM"
      },
      "source": [
        "# 損失関数と最適化手法を定義する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkZq2BPeJvlM"
      },
      "source": [
        "from utils.ssd_model import MultiBoxLoss\n",
        "\n",
        "# 損失関数の設定\n",
        "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
        "\n",
        "# 最適化手法の設定\n",
        "optimizer = optim.SGD(net.parameters(), lr=1e-3,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXpicFdQJvlN"
      },
      "source": [
        "# 学習の準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5BNcGMKJvlN"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # イテレーションカウンタをセット\n",
        "    iteration = 1\n",
        "    epoch_train_loss = 0.0  # epochの損失和\n",
        "    epoch_val_loss = 0.0  # epochの損失和\n",
        "    logs = []\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # 開始時刻を保存\n",
        "        t_epoch_start = time.time()\n",
        "        t_iter_start = time.time()\n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "                print('（train）')\n",
        "            else:\n",
        "                if((epoch+1) % 10 == 0):\n",
        "                    net.eval()   # モデルを検証モードに\n",
        "                    print('-------------')\n",
        "                    print('（val）')\n",
        "                else:\n",
        "                    # 検証は10回に1回だけ行う\n",
        "                    continue\n",
        "\n",
        "            # データローダーからminibatchずつ取り出すループ\n",
        "            for images, targets in dataloaders_dict[phase]:\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                images = images.to(device)\n",
        "                targets = [ann.to(device)\n",
        "                           for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # 順伝搬（forward）計算\n",
        "                    outputs = net(images)\n",
        "\n",
        "                    # 損失の計算\n",
        "                    loss_l, loss_c = criterion(outputs, targets)\n",
        "                    loss = loss_l + loss_c\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()  # 勾配の計算\n",
        "\n",
        "                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
        "                        nn.utils.clip_grad_value_(\n",
        "                            net.parameters(), clip_value=2.0)\n",
        "\n",
        "                        optimizer.step()  # パラメータ更新\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            t_iter_finish = time.time()\n",
        "                            duration = t_iter_finish - t_iter_start\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
        "                                iteration, loss.item(), duration))\n",
        "                            t_iter_start = time.time()\n",
        "\n",
        "                        epoch_train_loss += loss.item()\n",
        "                        iteration += 1\n",
        "\n",
        "                    # 検証時\n",
        "                    else:\n",
        "                        epoch_val_loss += loss.item()\n",
        "\n",
        "        # epochのphaseごとのloss （Issue158での誤植修正）\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
        "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "        # ログを保存\n",
        "        log_epoch = {'epoch': epoch+1,\n",
        "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
        "        logs.append(log_epoch)\n",
        "        df = pd.DataFrame(logs)\n",
        "        df.to_csv(\"log_output.csv\")\n",
        "\n",
        "        epoch_train_loss = 0.0  # epochの損失和\n",
        "        epoch_val_loss = 0.0  # epochの損失和\n",
        "\n",
        "        # ネットワークを保存する\n",
        "        if ((epoch+1) % 10 == 0):\n",
        "            torch.save(net.state_dict(), 'weights/ssd300_' +\n",
        "                       str(epoch+1) + '.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ff8ii0o7He3"
      },
      "source": [
        "# 学習の実行\n",
        "\n",
        "[U-Tsukuba] Extra remarks  \n",
        "\n",
        "You need probably 5-6 hours to run 50 epochs.  \n",
        "Maybe 10 epochs would be sufficient to see the behavior of the training phase here.  \n",
        "The spec of the runtime instance can be investigated by [100-ColabTutorial.ipynb](https://github.com/kameda-yoshinari/IMISToolExeA2021/blob/main/100_ColabTutorial.ipynb).\n",
        "\n",
        "As of 2021/07, Intel(R) Xeon(R) CPU @ 2.00GHz x 2 + Tesla T4 (15GB) would be a rumtime instance with GPU.\n",
        "\n",
        "(We can utilize the well-trained result (ssd300_50.pth) from the author's web site.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuOV3vkiJvlO"
      },
      "source": [
        "# 学習・検証を実行する\n",
        "\n",
        "# Just to surpress UserWarning\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "num_epochs= 10  \n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFnG0HBa8_QE"
      },
      "source": [
        "[U-Tsukuba] Extra remarks \n",
        "\n",
        "You can see the loss graph for 50 epochs in 図2.7.2 at P.121 in the textbook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAXU63BxJvlP"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCqS90sT9Z89"
      },
      "source": [
        "---\n",
        "Revised by KAMEDA, Yoshinari at University of Tsukuba for lecture purpose.  \n",
        "Original: https://github.com/YutaroOgawa/pytorch_advanced\n",
        "\n",
        "2021/08/02. "
      ]
    }
  ]
}