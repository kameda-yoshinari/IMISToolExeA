{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "GC7-6_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2022/blob/main/600/pytorch_advanced-revised/7_nlp_sentiment_transformer/GC7_6_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1PpwmcMJFRB"
      },
      "source": [
        "# 7.6  Transformerモデル（分類タスク用）の実装\n",
        "\n",
        "- 本ファイルでは、クラス分類のTransformerモデルを実装します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aSx2BwBJFRC"
      },
      "source": [
        "※　本章のファイルはすべてUbuntuでの動作を前提としています。Windowsなど文字コードが違う環境での動作にはご注意下さい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD2JfFFgJFRD"
      },
      "source": [
        "# 7.6 学習目標\n",
        "\n",
        "1.\tTransformerのモジュール構成を理解する\n",
        "2.\tLSTMやRNNを使用せずCNNベースのTransformerで自然言語処理が可能な理由を理解する\n",
        "3.\tTransformerを実装できるようになる\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Google Colab"
      ],
      "metadata": {
        "id": "QtUZ8UmUAhzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Change to the JST notation.\"\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Japan /etc/localtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQmzreTuAmHi",
        "outputId": "4f3a2344-d1f7-4add-db1e-ec0aedb03781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change to the JST notation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Start mounting your Google Drive.\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!echo \"Move to the working directory.\"\n",
        "%cd IMIS_Tool-A/Work600/\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyhlOfzHAqoz",
        "outputId": "d5dadd7a-0e25-4792-aafa-a3cc8e242c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start mounting your Google Drive.\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n",
            "Move to the working directory.\n",
            "/content/drive/My Drive/IMIS_Tool-A/Work600\n",
            "total 4\n",
            "drwx------ 2 root root 4096 Aug  7 22:01 pytorch_advanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 共通準備\n",
        "\n",
        "\"pytorch_advanced\" folder should be ready before you come here."
      ],
      "metadata": {
        "id": "J9slM624Atv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip this if you have already issued git in advance. \n",
        "# If you come here by way of 600-PyTorchADL.ipynb, \n",
        "# you should skip the git command (as you have already issued in 600).  \n",
        "# If you run git when pytorch_advanced already exists, git tells the error and clone won't be made.\n",
        "\n",
        "#!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced\"):\n",
        "    print(\"OK. Alreadly git cloned. You can go.\")\n",
        "else:\n",
        "    print(\"You'd better go back to the first 600-PyTorchADL.ipynb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvga5g3aAwM2",
        "outputId": "955303f9-9738-429c-8a40-4b1bdf079a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK. Alreadly git cloned. You can go.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRia6DwFx7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185d6490-6802-4721-fff7-3fa785246c16"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch_advanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGd5BWZZx7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322981e5-4dc4-4fb5-9c15-b60cbdf82d9a"
      },
      "source": [
        "%cd \"pytorch_advanced\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWF4QMix7tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d2dfa1-bcaa-4ce1-9ede-e1e397bd2361"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_image_classification\t 7_nlp_sentiment_transformer\n",
            "2_objectdetection\t 8_nlp_sentiment_bert\n",
            "3_semantic_segmentation  9_video_classification_eco\n",
            "4_pose_estimation\t etc\n",
            "5_gan_generation\t LICENSE\n",
            "6_gan_anomaly_detection  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YelRffxx7tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc4a7c2-7b0b-4131-fe69-b4fb7c1fe889"
      },
      "source": [
        "%cd \"7_nlp_sentiment_transformer\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced/7_nlp_sentiment_transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRZz7hVLx7tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4451d31a-09d8-4891-ea1a-adb808edfbf7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7-1_Tokenizer.ipynb\t\t   7-7_transformer_training_inference.ipynb\n",
            "7-2_torchtext.ipynb\t\t   data\n",
            "7-4_vectorize.ipynb\t\t   make_folders_and_data_downloads.ipynb\n",
            "7-5_IMDb_Dataset_DataLoader.ipynb  utils\n",
            "7-6_Transformer.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxprtbsK4RJw"
      },
      "source": [
        "---\n",
        "# Extraction of aclImdb (GC7-0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDD4Tx9b2htz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02eae8e4-2cfb-4418-e06b-7f9b7b833919"
      },
      "source": [
        "# local drive on GC is very, very fast.\n",
        "!mkdir -p /root/data/\n",
        "%cd /root/data/\n",
        "!tar xfz '/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced/7_nlp_sentiment_transformer/data/aclImdb_v1.tar.gz'\n",
        "\n",
        "# make a symbolic link at the working directory on google drive.\n",
        "%cd '/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced/7_nlp_sentiment_transformer/'\n",
        "!rm -f data/aclImdb\n",
        "!ln -s /root/data/aclImdb data/aclImdb\n",
        "\n",
        "!ls -ld data/aclImdb/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/data\n",
            "/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced/7_nlp_sentiment_transformer\n",
            "drwxr-xr-x 4 7297 1000 4096 Jun 26  2011 data/aclImdb/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jxOQXwjwVAj"
      },
      "source": [
        "# utils/dataloader.py\n",
        "\n",
        "utils/dataloader.py should be updated on 7-6_Transformer.ipynb ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0RtN3GGwpIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c18d1d-cde1-433c-a7a6-ead7c6b7e62e"
      },
      "source": [
        "!head -5 utils/dataloader.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 第7章 自然言語処理による感情分析（Transformer）\n",
            "\n",
            "\n",
            "import glob\n",
            "import os\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use torchtext version 0.8 (and torch 1.7.1) that was popular when the book was published. See issue 148.\n",
        "# https://github.com/YutaroOgawa/pytorch_advanced/issues/148\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "!pip uninstall -y torchtext torchvision torchaudio\n",
        "!pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchtext==0.8"
      ],
      "metadata": {
        "id": "NTX6iYh2IW38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb65f857-a14b-4744-f3d7-93c2d0375a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchtext 0.13.0\n",
            "Uninstalling torchtext-0.13.0:\n",
            "  Successfully uninstalled torchtext-0.13.0\n",
            "Found existing installation: torchvision 0.13.0+cu113\n",
            "Uninstalling torchvision-0.13.0+cu113:\n",
            "  Successfully uninstalled torchvision-0.13.0+cu113\n",
            "Found existing installation: torchaudio 0.12.0+cu113\n",
            "Uninstalling torchaudio-0.12.0+cu113:\n",
            "  Successfully uninstalled torchaudio-0.12.0+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.2 MB/s eta 0:04:31tcmalloc: large alloc 1147494400 bytes == 0x3a7bc000 @  0x7f91fd2cd615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.4 MB/s eta 0:01:13tcmalloc: large alloc 1434370048 bytes == 0x7ee12000 @  0x7f91fd2cd615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0xd45fe000 @  0x7f91fd2cd615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.21.6)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, which is not installed.\u001b[0m\n",
            "Successfully installed torch-1.7.1+cu110\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 15.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (1.7.1+cu110)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IBOjXDeJFRE"
      },
      "source": [
        "---\n",
        "# 事前準備\n",
        "書籍の指示に従い、本章で使用するデータを用意します\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1kMABqAJFRF"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2wc_IbWJFRI"
      },
      "source": [
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAB9spQJJFRM"
      },
      "source": [
        "class Embedder(nn.Module):\n",
        "    '''idで示されている単語をベクトルに変換します'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors):\n",
        "        super(Embedder, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding.from_pretrained(\n",
        "            embeddings=text_embedding_vectors, freeze=True)\n",
        "        # freeze=Trueによりバックプロパゲーションで更新されず変化しなくなります\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_vec = self.embeddings(x)\n",
        "\n",
        "        return x_vec\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import io\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import spacy\n",
        "import torchtext\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "\n",
        "def get_IMDb_DataLoaders_and_TEXT(max_length=256, batch_size=24):\n",
        "    \"\"\"IMDbのDataLoaderとTEXTオブジェクトを取得する。 \"\"\"\n",
        "\n",
        "    # 訓練データのtsvファイルを作成します\n",
        "    f = open('./data/IMDb_train.tsv', 'w')\n",
        "\n",
        "    path = './data/aclImdb/train/pos/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/train/neg/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    f.close()\n",
        "\n",
        "   # テストデータの作成\n",
        "    f = open('./data/IMDb_test.tsv', 'w')\n",
        "\n",
        "    path = './data/aclImdb/test/pos/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/test/neg/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "    f.close()\n",
        "\n",
        "    def preprocessing_text(text):\n",
        "        # 改行コードを消去\n",
        "        text = re.sub('<br />', '', text)\n",
        "\n",
        "        # カンマ、ピリオド以外の記号をスペースに置換\n",
        "        for p in string.punctuation:\n",
        "            if (p == \".\") or (p == \",\"):\n",
        "                continue\n",
        "            else:\n",
        "                text = text.replace(p, \" \")\n",
        "\n",
        "        # ピリオドなどの前後にはスペースを入れておく\n",
        "        text = text.replace(\".\", \" . \")\n",
        "        text = text.replace(\",\", \" , \")\n",
        "        return text\n",
        "\n",
        "    # 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
        "    def tokenizer_punctuation(text):\n",
        "        return text.strip().split()\n",
        "\n",
        "\n",
        "    # 前処理と分かち書きをまとめた関数を定義\n",
        "    def tokenizer_with_preprocessing(text):\n",
        "        text = preprocessing_text(text)\n",
        "        ret = tokenizer_punctuation(text)\n",
        "        return ret\n",
        "\n",
        "\n",
        "    # データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "    # max_length\n",
        "    TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                                lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"<cls>\", eos_token=\"<eos>\")\n",
        "    LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "    # フォルダ「data」から各tsvファイルを読み込みます\n",
        "    train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "        path='./data/', train='IMDb_train.tsv',\n",
        "        test='IMDb_test.tsv', format='tsv',\n",
        "        fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "    # torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\n",
        "    train_ds, val_ds = train_val_ds.split(\n",
        "        split_ratio=0.8, random_state=random.seed(1234))\n",
        "\n",
        "    # torchtextで単語ベクトルとして英語学習済みモデルを読み込みます\n",
        "    english_fasttext_vectors = Vectors(name='data/wiki-news-300d-1M.vec')\n",
        "\n",
        "    # ベクトル化したバージョンのボキャブラリーを作成します\n",
        "    TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors, min_freq=10)\n",
        "\n",
        "    # DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "    train_dl = torchtext.data.Iterator(\n",
        "        train_ds, batch_size=batch_size, train=True)\n",
        "\n",
        "    val_dl = torchtext.data.Iterator(\n",
        "        val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "    test_dl = torchtext.data.Iterator(\n",
        "        test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "    return train_dl, val_dl, test_dl, TEXT"
      ],
      "metadata": {
        "id": "gFc2ghQnEU_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loHdRkRaJFRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28026c2-65ea-4c7c-9acd-d4562b38287c"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# 前節のDataLoaderなどを取得\n",
        "#from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
        "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
        "    max_length=256, batch_size=24)\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x.shape)\n",
        "print(\"出力のテンソルサイズ：\", x1.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力のテンソルサイズ： torch.Size([24, 256])\n",
            "出力のテンソルサイズ： torch.Size([24, 256, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-R3xrLWJFRU"
      },
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
        "\n",
        "    def __init__(self, d_model=300, max_seq_len=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model  # 単語ベクトルの次元数\n",
        "\n",
        "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # pe = pe.to(device)\n",
        "\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                \n",
        "                # 誤植修正_200510 #79\n",
        "                # pe[pos, i + 1] = math.cos(pos /\n",
        "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos /\n",
        "                                          (10000 ** ((2 * i)/d_model)))\n",
        "\n",
        "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "        # 勾配を計算しないようにする\n",
        "        self.pe.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 入力xとPositonal Encodingを足し算する\n",
        "        # xがpeよりも小さいので、大きくする\n",
        "        ret = math.sqrt(self.d_model)*x + self.pe\n",
        "        return ret\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZoqYmiiJFRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb614fa4-fda8-446c-d77f-b2bf1c7b1eb5"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "x2 = net2(x1)\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x1.shape)\n",
        "print(\"出力のテンソルサイズ：\", x2.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "出力のテンソルサイズ： torch.Size([24, 256, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8wcSoeDJFRa"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    '''Transformerは本当はマルチヘッドAttentionですが、\n",
        "    分かりやすさを優先しシングルAttentionで実装します'''\n",
        "\n",
        "    def __init__(self, d_model=300):\n",
        "        super().__init__()\n",
        "\n",
        "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # 出力時に使用する全結合層\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Attentionの大きさ調整の変数\n",
        "        self.d_k = d_model\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        # 全結合層で特徴量を変換\n",
        "        k = self.k_linear(k)\n",
        "        q = self.q_linear(q)\n",
        "        v = self.v_linear(v)\n",
        "\n",
        "        # Attentionの値を計算する\n",
        "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
        "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # ここでmaskを計算\n",
        "        mask = mask.unsqueeze(1)\n",
        "        weights = weights.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # softmaxで規格化をする\n",
        "        normlized_weights = F.softmax(weights, dim=-1)\n",
        "\n",
        "        # AttentionをValueとかけ算\n",
        "        output = torch.matmul(normlized_weights, v)\n",
        "\n",
        "        # 全結合層で特徴量を変換\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, normlized_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1AcDAfjJFRe"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
        "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.dropout(F.relu(x))\n",
        "        x = self.linear_2(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ5Y2sDDJFRh"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # LayerNormalization層\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Attention層\n",
        "        self.attn = Attention(d_model)\n",
        "\n",
        "        # Attentionのあとの全結合層2つ\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # 正規化とAttention\n",
        "        x_normlized = self.norm_1(x)\n",
        "        output, normlized_weights = self.attn(\n",
        "            x_normlized, x_normlized, x_normlized, mask)\n",
        "        \n",
        "        x2 = x + self.dropout_1(output)\n",
        "\n",
        "        # 正規化と全結合層\n",
        "        x_normlized2 = self.norm_2(x2)\n",
        "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
        "\n",
        "        return output, normlized_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNaVWuNJJFRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2db581c-0cbe-44d9-f4c7-d71b1039a536"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "\n",
        "# maskの作成\n",
        "x = batch.Text[0]\n",
        "input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
        "input_mask = (x != input_pad)\n",
        "print(input_mask[0])\n",
        "\n",
        "# 入出力\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "x2 = net2(x1)  # Positon情報を足し算\n",
        "x3, normlized_weights = net3(x2, input_mask)  # Self-Attentionで特徴量を変換\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x2.shape)\n",
        "print(\"出力のテンソルサイズ：\", x3.shape)\n",
        "print(\"Attentionのサイズ：\", normlized_weights.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False])\n",
            "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "出力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "Attentionのサイズ： torch.Size([24, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcrNM1rpJFRn"
      },
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
        "\n",
        "    def __init__(self, d_model=300, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # 全結合層\n",
        "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.linear.weight, std=0.02)\n",
        "        nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
        "        out = self.linear(x0)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUVS-wxoJFRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bf489c-5413-4851-8fb5-516af4bd70c9"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# モデル構築\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "net4 = ClassificationHead(output_dim=2, d_model=300)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 単語をベクトルに\n",
        "x2 = net2(x1)  # Positon情報を足し算\n",
        "x3, normlized_weights = net3(x2, input_mask)  # Self-Attentionで特徴量を変換\n",
        "x4 = net4(x3)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x3.shape)\n",
        "print(\"出力のテンソルサイズ：\", x4.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
            "出力のテンソルサイズ： torch.Size([24, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8-NHGc3JFRt"
      },
      "source": [
        "# 最終的なTransformerモデルのクラス\n",
        "\n",
        "\n",
        "class TransformerClassification(nn.Module):\n",
        "    '''Transformerでクラス分類させる'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # モデル構築\n",
        "        self.net1 = Embedder(text_embedding_vectors)\n",
        "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
        "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
        "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
        "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x1 = self.net1(x)  # 単語をベクトルに\n",
        "        x2 = self.net2(x1)  # Positon情報を足し算\n",
        "        x3_1, normlized_weights_1 = self.net3_1(\n",
        "            x2, mask)  # Self-Attentionで特徴量を変換\n",
        "        x3_2, normlized_weights_2 = self.net3_2(\n",
        "            x3_1, mask)  # Self-Attentionで特徴量を変換\n",
        "        x4 = self.net4(x3_2)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
        "        return x4, normlized_weights_1, normlized_weights_2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2dt7_rvJFRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e3a797-7739-4291-bb2d-3f683dac6eb1"
      },
      "source": [
        "# 動作確認\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(train_dl))\n",
        "\n",
        "# モデル構築\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "input_mask = (x != input_pad)\n",
        "out, normlized_weights_1, normlized_weights_2 = net(x, input_mask)\n",
        "\n",
        "print(\"出力のテンソルサイズ：\", out.shape)\n",
        "print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "出力のテンソルサイズ： torch.Size([24, 2])\n",
            "出力テンソルのsigmoid： tensor([[0.6936, 0.3064],\n",
            "        [0.7261, 0.2739],\n",
            "        [0.7221, 0.2779],\n",
            "        [0.6977, 0.3023],\n",
            "        [0.6906, 0.3094],\n",
            "        [0.6926, 0.3074],\n",
            "        [0.6794, 0.3206],\n",
            "        [0.6572, 0.3428],\n",
            "        [0.7134, 0.2866],\n",
            "        [0.7175, 0.2825],\n",
            "        [0.7151, 0.2849],\n",
            "        [0.7003, 0.2997],\n",
            "        [0.6753, 0.3247],\n",
            "        [0.7077, 0.2923],\n",
            "        [0.7271, 0.2729],\n",
            "        [0.6840, 0.3160],\n",
            "        [0.6991, 0.3009],\n",
            "        [0.6945, 0.3055],\n",
            "        [0.6894, 0.3106],\n",
            "        [0.7188, 0.2812],\n",
            "        [0.7189, 0.2811],\n",
            "        [0.7364, 0.2636],\n",
            "        [0.6759, 0.3241],\n",
            "        [0.7243, 0.2757]], grad_fn=<SoftmaxBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSSYMFxdJFRx"
      },
      "source": [
        "ここまでの内容をフォルダ「utils」のtransformer.pyに別途保存しておき、次節からはこちらから読み込むようにします"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLg9VGIJFRx"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Revised by KAMEDA, Yoshinari at University of Tsukuba for lecture purpose.  \n",
        "Original: https://github.com/YutaroOgawa/pytorch_advanced\n",
        "\n",
        "2022/08/08.  "
      ],
      "metadata": {
        "id": "B7vxbABSaDwm"
      }
    }
  ]
}