{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "GC4-6_OpenPose_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2021/blob/main/600/pytorch_advanced-revised/4_pose_estimation/GC4_6_OpenPose_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HMd35_2SDgW"
      },
      "source": [
        "# 4.6 学習と検証の実施\n",
        "\n",
        "- 本ファイルでは、OpenPoseの学習と検証の実施を行います。AWSのGPUマシンで計算します。\n",
        "- p2.xlargeで45分ほどかかります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnyFwQr3SDgZ"
      },
      "source": [
        "# 学習目標\n",
        "\n",
        "1.\tOpenPoseの学習を実装できるようになる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z2iYK_ox7s-"
      },
      "source": [
        "---\n",
        "\n",
        "# Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p12QTDHEx7tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a471bb-f394-43f0-edc1-9c07c7527488"
      },
      "source": [
        "!echo \"Change to the JST notation.\"\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Japan /etc/localtime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Change to the JST notation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usdzzcLbx7tI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b90627-d998-465f-a73a-9a655a7e1ec2"
      },
      "source": [
        "!echo \"Start mounting your Google Drive.\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!echo \"Move to the working directory.\"\n",
        "%cd 202107_Tool-A/Work600/\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start mounting your Google Drive.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n",
            "Move to the working directory.\n",
            "/content/drive/My Drive/202107_Tool-A/Work600\n",
            "total 4\n",
            "drwx------ 13 root root 4096 Jul 31 09:41 pytorch_advanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDc3dnE_x7tJ"
      },
      "source": [
        "---\n",
        "# 共通準備\n",
        "\n",
        "\"pytorch_advanced\" folder should be ready before you come here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cED0rxM7x7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5bfc91-6e8f-4174-dbf5-0f9b71f17ac2"
      },
      "source": [
        "# Skip this if you have already issued git in advance. \n",
        "# If you come here by way of 600-PyTorchADL.ipynb, \n",
        "# you should skip the git command (as you have already issued in 600).  \n",
        "# If you run git when pytorch_advanced already exists, git tells the error and clone won't be made.\n",
        "\n",
        "#!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced\"):\n",
        "    print(\"OK. Alreadly git cloned. You can go.\")\n",
        "else:\n",
        "    print(\"You'd better go back to the first 600-PyTorchADL.ipynb\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK. Alreadly git cloned. You can go.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRia6DwFx7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0de6993-0a91-4a5d-a094-94fc0814639d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytorch_advanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGd5BWZZx7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a73758-be67-4cd6-9b18-3d825b65f707"
      },
      "source": [
        "%cd \"pytorch_advanced\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWF4QMix7tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d738252d-c00e-4e32-886b-310c53b64975"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1_image_classification\t 7_nlp_sentiment_transformer\n",
            "2_objectdetection\t 8_nlp_sentiment_bert\n",
            "3_semantic_segmentation  9_video_classification_eco\n",
            "4_pose_estimation\t etc\n",
            "5_gan_generation\t LICENSE\n",
            "6_gan_anomaly_detection  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YelRffxx7tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d41307-168c-465c-9b1c-763a57f4a305"
      },
      "source": [
        "%cd \"4_pose_estimation\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRZz7hVLx7tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b392f8-466e-4cd6-944c-46b01f1e2151"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4-2_DataLoader.ipynb\t     4-7_OpenPose_inference.ipynb\t    utils\n",
            "4-3-4_NetworkModel.ipynb     data\t\t\t\t    weights\n",
            "4-5_TensorBoardX.ipynb\t     make_folders_and_data_downloads.ipynb\n",
            "4-6_OpenPose_training.ipynb  tbX\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCElkS-f3p-v"
      },
      "source": [
        "---\n",
        "# Utils, Data, and Weights\n",
        "\n",
        "Working directories are:\n",
        "\n",
        "* /root/utils  \n",
        "* /root/data  \n",
        "* /root/weights  \n",
        "\n",
        "val2014.zip and mask.tar.gz are expanded there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T1Dk6II1n8-",
        "outputId": "7be27839-0776-441c-9a15-b479aaaedbd3"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2628\n",
            "-rw------- 1 root root 1273983 Jul 31 09:42 4-2_DataLoader.ipynb\n",
            "-rw------- 1 root root  150239 Jul 31 09:42 4-3-4_NetworkModel.ipynb\n",
            "-rw------- 1 root root   15393 Jul 31 09:42 4-5_TensorBoardX.ipynb\n",
            "-rw------- 1 root root   14793 Jul 31 09:42 4-6_OpenPose_training.ipynb\n",
            "-rw------- 1 root root 1213399 Jul 31 09:42 4-7_OpenPose_inference.ipynb\n",
            "drwx------ 2 root root    4096 Jul 31 09:42 data\n",
            "-rw------- 1 root root    5310 Jul 31 09:42 make_folders_and_data_downloads.ipynb\n",
            "drwx------ 2 root root    4096 Aug  1 14:51 tbX\n",
            "drwx------ 3 root root    4096 Jul 31 09:42 utils\n",
            "drwx------ 2 root root    4096 Aug  1 12:49 weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMH-_2g34yS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dee9230-c35d-44bb-a53b-9aeac15eded3"
      },
      "source": [
        "# This will take 8 minutes.\n",
        "\n",
        "%cd ~\n",
        "\n",
        "!cp -r '/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation/utils/'   .\n",
        "!cp -r '/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation/data/'    .\n",
        "!cp -r '/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation/weights/' .\n",
        "\n",
        "%cd data\n",
        "!unzip -q -o  val2014.zip\n",
        "!tar xfz mask.tar.gz\n",
        "\n",
        "%cd ~"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dg4_dOq6Yz-"
      },
      "source": [
        "!ls -l utils data weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUgqXfGVSDgZ"
      },
      "source": [
        "---\n",
        "# 事前準備\n",
        "\n",
        "- これまでの章で実装したクラスと関数をフォルダ「utils」内に用意しています\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-B02Z7sSDgZ"
      },
      "source": [
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwgD1TNfSDga"
      },
      "source": [
        "# 初期設定\n",
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVRCRyZYSDga"
      },
      "source": [
        "# DataLoader作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEm5sB1gSDgb"
      },
      "source": [
        "# about 30 sec\n",
        "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
        "\n",
        "# MS COCOのファイルパスリスト作成\n",
        "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(\n",
        "    rootpath=\"./data/\")\n",
        "\n",
        "# Dataset作成\n",
        "# 本書ではデータ量の問題から、trainをval_listで作成している点に注意\n",
        "train_dataset = COCOkeypointsDataset(\n",
        "    val_img_list, val_mask_list, val_meta_list, phase=\"train\", transform=DataTransform())\n",
        "\n",
        "# 今回は簡易な学習とし検証データは作成しない\n",
        "# val_dataset = CocokeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
        "\n",
        "# DataLoader作成\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# val_dataloader = data.DataLoader(\n",
        "#    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数にまとめる\n",
        "# dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": None}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKqLnnDDSDgb"
      },
      "source": [
        "# ネットワークモデル作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7SMZVquSDgb"
      },
      "source": [
        "from utils.openpose_net import OpenPoseNet\n",
        "net = OpenPoseNet()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G20GTUp3SDgc"
      },
      "source": [
        "# 損失関数を定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FZRggmmSDgc"
      },
      "source": [
        "# 損失関数の設定\n",
        "class OpenPoseLoss(nn.Module):\n",
        "    \"\"\"OpenPoseの損失関数のクラスです。\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(OpenPoseLoss, self).__init__()\n",
        "\n",
        "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
        "        \"\"\"\n",
        "        損失関数の計算。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        saved_for_loss : OpenPoseNetの出力(リスト)\n",
        "\n",
        "        heatmap_target : [num_batch, 19, 46, 46]\n",
        "            正解の部位のアノテーション情報\n",
        "\n",
        "        heatmap_mask : [num_batch, 19, 46, 46]\n",
        "            heatmap画像のmask\n",
        "\n",
        "        paf_target : [num_batch, 38, 46, 46]\n",
        "            正解のPAFのアノテーション情報\n",
        "\n",
        "        paf_mask : [num_batch, 38, 46, 46]\n",
        "            PAF画像のmask\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : テンソル\n",
        "            損失の値\n",
        "        \"\"\"\n",
        "\n",
        "        total_loss = 0\n",
        "        # ステージごとに計算します\n",
        "        for j in range(6):\n",
        "\n",
        "            # PAFsとheatmapsにおいて、マスクされている部分（paf_mask=0など）は無視させる\n",
        "            # PAFs\n",
        "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
        "            gt1 = paf_target.float() * paf_mask\n",
        "\n",
        "            # heatmaps\n",
        "            pred2 = saved_for_loss[2 * j + 1] * heat_mask\n",
        "            gt2 = heatmap_target.float()*heat_mask\n",
        "\n",
        "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
        "                F.mse_loss(pred2, gt2, reduction='mean')\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "criterion = OpenPoseLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUUEhx42SDgd"
      },
      "source": [
        "# 最適化手法を設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoJRt16PSDgd"
      },
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=1e-2,\n",
        "                      momentum=0.9,\n",
        "                      weight_decay=0.0001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yh0tVX9SDgd"
      },
      "source": [
        "# 学習を実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYtNNK74SDgd"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # 画像の枚数\n",
        "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # イテレーションカウンタをセット\n",
        "    iteration = 1\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # 開始時刻を保存\n",
        "        t_epoch_start = time.time()\n",
        "        t_iter_start = time.time()\n",
        "        epoch_train_loss = 0.0  # epochの損失和\n",
        "        epoch_val_loss = 0.0  # epochの損失和\n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "                optimizer.zero_grad()\n",
        "                print('（train）')\n",
        "\n",
        "            # 今回は検証はスキップ\n",
        "            else:\n",
        "                continue\n",
        "                # net.eval()   # モデルを検証モードに\n",
        "                # print('-------------')\n",
        "                # print('（val）')\n",
        "\n",
        "            # データローダーからminibatchずつ取り出すループ\n",
        "            for imges, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
        "                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
        "                if imges.size()[0] == 1:\n",
        "                    continue\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                imges = imges.to(device)\n",
        "                heatmap_target = heatmap_target.to(device)\n",
        "                heat_mask = heat_mask.to(device)\n",
        "                paf_target = paf_target.to(device)\n",
        "                paf_mask = paf_mask.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # (out6_1, out6_2)は使わないので _ で代替\n",
        "                    _, saved_for_loss = net(imges)\n",
        "\n",
        "                    loss = criterion(saved_for_loss, heatmap_target,\n",
        "                                     heat_mask, paf_target, paf_mask)\n",
        "                    del saved_for_loss\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            t_iter_finish = time.time()\n",
        "                            duration = t_iter_finish - t_iter_start\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
        "                                iteration, loss.item()/batch_size, duration))\n",
        "                            t_iter_start = time.time()\n",
        "\n",
        "                        epoch_train_loss += loss.item()\n",
        "                        iteration += 1\n",
        "\n",
        "                    # 検証時\n",
        "                    # else:\n",
        "                        #epoch_val_loss += loss.item()\n",
        "\n",
        "        # epochのphaseごとのlossと正解率\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
        "            epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "    # 最後のネットワークを保存する\n",
        "    torch.save(net.state_dict(), 'weights/openpose_net_' +\n",
        "               str(epoch+1) + '.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wMHxTsBSDgf"
      },
      "source": [
        "# 学習・検証を実行する\n",
        "# 学習の雰囲気を感じるためだけなので、学習セットも小さくecoch数も小さい\n",
        "# It will take 50 minutes or so (25 min per epoch).\n",
        "\n",
        "# Just to surpress UserWarning\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "num_epochs = 2\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZvBbF3gSDgg"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1414w3bCecc"
      },
      "source": [
        "---\n",
        "Revised by KAMEDA, Yoshinari at University of Tsukuba for lecture purpose.  \n",
        "Original: https://github.com/YutaroOgawa/pytorch_advanced\n",
        "\n",
        "2021/08/02. "
      ]
    }
  ]
}