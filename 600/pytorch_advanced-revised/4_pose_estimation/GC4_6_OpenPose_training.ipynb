{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "GC4-6_OpenPose_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2021/blob/main/600/pytorch_advanced-revised/4_pose_estimation/GC4_6_OpenPose_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HMd35_2SDgW"
      },
      "source": [
        "# 4.6 学習と検証の実施\n",
        "\n",
        "- 本ファイルでは、OpenPoseの学習と検証の実施を行います。AWSのGPUマシンで計算します。\n",
        "- p2.xlargeで45分ほどかかります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnyFwQr3SDgZ"
      },
      "source": [
        "# 学習目標\n",
        "\n",
        "1.\tOpenPoseの学習を実装できるようになる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z2iYK_ox7s-"
      },
      "source": [
        "---\n",
        "\n",
        "# Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p12QTDHEx7tH"
      },
      "source": [
        "!echo \"Change to the JST notation.\"\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Japan /etc/localtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usdzzcLbx7tI"
      },
      "source": [
        "!echo \"Start mounting your Google Drive.\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!echo \"Move to the working directory.\"\n",
        "%cd 202107_Tool-A/Work600/\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDc3dnE_x7tJ"
      },
      "source": [
        "---\n",
        "# 共通準備\n",
        "\n",
        "\"pytorch_advanced\" folder should be ready before you come here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cED0rxM7x7tJ"
      },
      "source": [
        "# Skip this if you have already issued git in advance. \n",
        "# If you come here by way of 600-PyTorchADL.ipynb, \n",
        "# you should skip the git command (as you have already issued in 600).  \n",
        "# If you run git when pytorch_advanced already exists, git tells the error and clone won't be made.\n",
        "\n",
        "#!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced\"):\n",
        "    print(\"OK. Alreadly git cloned. You can go.\")\n",
        "else:\n",
        "    print(\"You'd better go back to the first 600-PyTorchADL.ipynb\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRia6DwFx7tJ"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGd5BWZZx7tJ"
      },
      "source": [
        "%cd \"pytorch_advanced\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWF4QMix7tK"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YelRffxx7tK"
      },
      "source": [
        "%cd \"4_pose_estimation\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRZz7hVLx7tK"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PkHjWeV-cpi"
      },
      "source": [
        "---\n",
        "# Data extraction\n",
        "\n",
        "val2014.zip and mask.tar.gz are expanded here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OHg_wVA-cpl"
      },
      "source": [
        "# it takes 6 minutes or so.\n",
        "\n",
        "!mkdir -p /root/data\n",
        "%cd       /root/data\n",
        "!tar xfz '/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation/data/mask.tar.gz'\n",
        "# 40504 image files, 6GB or over in total\n",
        "!unzip -q -u '/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation/data/val2014.zip'\n",
        "\n",
        "%cd '/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/4_pose_estimation/'\n",
        "!rm -f data/val2014 data/mask\n",
        "!ln -s /root/data/val2014 data/val2014\n",
        "!ln -s /root/data/mask data/mask\n",
        "\n",
        "!ls -ld data/val2014/ data/mask/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9HghHN-cpm"
      },
      "source": [
        "!ls -l utils data weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUgqXfGVSDgZ"
      },
      "source": [
        "---\n",
        "# 事前準備\n",
        "\n",
        "- これまでの章で実装したクラスと関数をフォルダ「utils」内に用意しています\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-B02Z7sSDgZ"
      },
      "source": [
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwgD1TNfSDga"
      },
      "source": [
        "# 初期設定\n",
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVRCRyZYSDga"
      },
      "source": [
        "# DataLoader作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEm5sB1gSDgb"
      },
      "source": [
        "# about 30 sec\n",
        "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
        "\n",
        "# MS COCOのファイルパスリスト作成\n",
        "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(\n",
        "    rootpath=\"./data/\")\n",
        "\n",
        "# Dataset作成\n",
        "# 本書ではデータ量の問題から、trainをval_listで作成している点に注意\n",
        "train_dataset = COCOkeypointsDataset(\n",
        "    val_img_list, val_mask_list, val_meta_list, phase=\"train\", transform=DataTransform())\n",
        "\n",
        "# 今回は簡易な学習とし検証データは作成しない\n",
        "# val_dataset = CocokeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
        "\n",
        "# DataLoader作成\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# val_dataloader = data.DataLoader(\n",
        "#    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数にまとめる\n",
        "# dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": None}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKqLnnDDSDgb"
      },
      "source": [
        "# ネットワークモデル作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7SMZVquSDgb"
      },
      "source": [
        "from utils.openpose_net import OpenPoseNet\n",
        "net = OpenPoseNet()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G20GTUp3SDgc"
      },
      "source": [
        "# 損失関数を定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FZRggmmSDgc"
      },
      "source": [
        "# 損失関数の設定\n",
        "class OpenPoseLoss(nn.Module):\n",
        "    \"\"\"OpenPoseの損失関数のクラスです。\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(OpenPoseLoss, self).__init__()\n",
        "\n",
        "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
        "        \"\"\"\n",
        "        損失関数の計算。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        saved_for_loss : OpenPoseNetの出力(リスト)\n",
        "\n",
        "        heatmap_target : [num_batch, 19, 46, 46]\n",
        "            正解の部位のアノテーション情報\n",
        "\n",
        "        heatmap_mask : [num_batch, 19, 46, 46]\n",
        "            heatmap画像のmask\n",
        "\n",
        "        paf_target : [num_batch, 38, 46, 46]\n",
        "            正解のPAFのアノテーション情報\n",
        "\n",
        "        paf_mask : [num_batch, 38, 46, 46]\n",
        "            PAF画像のmask\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : テンソル\n",
        "            損失の値\n",
        "        \"\"\"\n",
        "\n",
        "        total_loss = 0\n",
        "        # ステージごとに計算します\n",
        "        for j in range(6):\n",
        "\n",
        "            # PAFsとheatmapsにおいて、マスクされている部分（paf_mask=0など）は無視させる\n",
        "            # PAFs\n",
        "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
        "            gt1 = paf_target.float() * paf_mask\n",
        "\n",
        "            # heatmaps\n",
        "            pred2 = saved_for_loss[2 * j + 1] * heat_mask\n",
        "            gt2 = heatmap_target.float()*heat_mask\n",
        "\n",
        "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
        "                F.mse_loss(pred2, gt2, reduction='mean')\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "criterion = OpenPoseLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUUEhx42SDgd"
      },
      "source": [
        "# 最適化手法を設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoJRt16PSDgd"
      },
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=1e-2,\n",
        "                      momentum=0.9,\n",
        "                      weight_decay=0.0001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yh0tVX9SDgd"
      },
      "source": [
        "# 学習を実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYtNNK74SDgd"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # 画像の枚数\n",
        "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # イテレーションカウンタをセット\n",
        "    iteration = 1\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # 開始時刻を保存\n",
        "        t_epoch_start = time.time()\n",
        "        t_iter_start = time.time()\n",
        "        epoch_train_loss = 0.0  # epochの損失和\n",
        "        epoch_val_loss = 0.0  # epochの損失和\n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "                optimizer.zero_grad()\n",
        "                print('（train）')\n",
        "\n",
        "            # 今回は検証はスキップ\n",
        "            else:\n",
        "                continue\n",
        "                # net.eval()   # モデルを検証モードに\n",
        "                # print('-------------')\n",
        "                # print('（val）')\n",
        "\n",
        "            # データローダーからminibatchずつ取り出すループ\n",
        "            for imges, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
        "                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
        "                if imges.size()[0] == 1:\n",
        "                    continue\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                imges = imges.to(device)\n",
        "                heatmap_target = heatmap_target.to(device)\n",
        "                heat_mask = heat_mask.to(device)\n",
        "                paf_target = paf_target.to(device)\n",
        "                paf_mask = paf_mask.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # (out6_1, out6_2)は使わないので _ で代替\n",
        "                    _, saved_for_loss = net(imges)\n",
        "\n",
        "                    loss = criterion(saved_for_loss, heatmap_target,\n",
        "                                     heat_mask, paf_target, paf_mask)\n",
        "                    del saved_for_loss\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            t_iter_finish = time.time()\n",
        "                            duration = t_iter_finish - t_iter_start\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
        "                                iteration, loss.item()/batch_size, duration))\n",
        "                            t_iter_start = time.time()\n",
        "\n",
        "                        epoch_train_loss += loss.item()\n",
        "                        iteration += 1\n",
        "\n",
        "                    # 検証時\n",
        "                    # else:\n",
        "                        #epoch_val_loss += loss.item()\n",
        "\n",
        "        # epochのphaseごとのlossと正解率\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
        "            epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "    # 最後のネットワークを保存する\n",
        "    torch.save(net.state_dict(), 'weights/openpose_net_' +\n",
        "               str(epoch+1) + '.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wMHxTsBSDgf"
      },
      "source": [
        "# 学習・検証を実行する\n",
        "# 学習の雰囲気を感じるためだけなので、学習セットも小さくecoch数も小さい\n",
        "# It will take 50 minutes or so (15-25 min per epoch).\n",
        "\n",
        "# Just to surpress UserWarning\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "num_epochs = 2\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZvBbF3gSDgg"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1414w3bCecc"
      },
      "source": [
        "---\n",
        "Revised by KAMEDA, Yoshinari at University of Tsukuba for lecture purpose.  \n",
        "Original: https://github.com/YutaroOgawa/pytorch_advanced\n",
        "\n",
        "2021/08/03. Use of symbolic link on google drive.  \n",
        "2021/08/02. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYZZJg7LQK5P"
      },
      "source": [
        "---\n",
        "---\n",
        "A result of GC with GPU\n",
        "\n",
        "15 min per epoch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBSv2E2wQXRi"
      },
      "source": [
        "<pre>\n",
        "使用デバイス： cuda:0\n",
        "-------------\n",
        "Epoch 1/2\n",
        "-------------\n",
        "（train）\n",
        "イテレーション 10 || Loss: 0.0093 || 10iter: 63.0731 sec.\n",
        "イテレーション 20 || Loss: 0.0082 || 10iter: 54.0383 sec.\n",
        "イテレーション 30 || Loss: 0.0068 || 10iter: 53.6469 sec.\n",
        "イテレーション 40 || Loss: 0.0057 || 10iter: 52.4185 sec.\n",
        "イテレーション 50 || Loss: 0.0048 || 10iter: 52.9386 sec.\n",
        "イテレーション 60 || Loss: 0.0044 || 10iter: 54.6460 sec.\n",
        "イテレーション 70 || Loss: 0.0037 || 10iter: 59.3785 sec.\n",
        "イテレーション 80 || Loss: 0.0030 || 10iter: 57.2215 sec.\n",
        "イテレーション 90 || Loss: 0.0027 || 10iter: 54.8535 sec.\n",
        "イテレーション 100 || Loss: 0.0026 || 10iter: 54.8580 sec.\n",
        "イテレーション 110 || Loss: 0.0021 || 10iter: 56.1912 sec.\n",
        "イテレーション 120 || Loss: 0.0022 || 10iter: 54.7837 sec.\n",
        "イテレーション 130 || Loss: 0.0020 || 10iter: 53.8752 sec.\n",
        "イテレーション 140 || Loss: 0.0018 || 10iter: 55.0608 sec.\n",
        "イテレーション 150 || Loss: 0.0019 || 10iter: 55.9013 sec.\n",
        "-------------\n",
        "epoch 1 || Epoch_TRAIN_Loss:0.0043 ||Epoch_VAL_Loss:0.0000\n",
        "timer:  863.3210 sec.\n",
        "-------------\n",
        "Epoch 2/2\n",
        "-------------\n",
        "（train）\n",
        "イテレーション 160 || Loss: 0.0017 || 10iter: 37.2756 sec.\n",
        "イテレーション 170 || Loss: 0.0016 || 10iter: 54.2178 sec.\n",
        "イテレーション 180 || Loss: 0.0020 || 10iter: 57.9946 sec.\n",
        "イテレーション 190 || Loss: 0.0016 || 10iter: 52.8687 sec.\n",
        "イテレーション 200 || Loss: 0.0016 || 10iter: 54.8009 sec.\n",
        "イテレーション 210 || Loss: 0.0014 || 10iter: 55.8420 sec.\n",
        "イテレーション 220 || Loss: 0.0017 || 10iter: 54.6562 sec.\n",
        "イテレーション 230 || Loss: 0.0013 || 10iter: 55.3755 sec.\n",
        "イテレーション 240 || Loss: 0.0013 || 10iter: 52.3853 sec.\n",
        "イテレーション 250 || Loss: 0.0015 || 10iter: 53.7750 sec.\n",
        "イテレーション 260 || Loss: 0.0013 || 10iter: 52.1475 sec.\n",
        "イテレーション 270 || Loss: 0.0016 || 10iter: 52.9654 sec.\n",
        "イテレーション 280 || Loss: 0.0015 || 10iter: 53.7876 sec.\n",
        "イテレーション 290 || Loss: 0.0014 || 10iter: 50.9517 sec.\n",
        "イテレーション 300 || Loss: 0.0014 || 10iter: 56.6291 sec.\n",
        "-------------\n",
        "epoch 2 || Epoch_TRAIN_Loss:0.0015 ||Epoch_VAL_Loss:0.0000\n",
        "timer:  840.3378 sec."
      ]
    }
  ]
}