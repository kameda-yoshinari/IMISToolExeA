{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "GC3-8_PSPNet_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2021/blob/main/600/pytorch_advanced-revised/3_semantic_segmentation/GC3_8_PSPNet_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl6l5r8siMJ-"
      },
      "source": [
        "# 3.8 推論の実施\n",
        "\n",
        "- 本ファイルでは、学習させたPSPNetでセマンティックセグメンテーションを行います。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn2yMYKiiMJ_"
      },
      "source": [
        "# 学習目標\n",
        "\n",
        "\n",
        "1.\tセマンティックセグメンテーションの推論を実装できるようになる\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRUqU4tnxmZl"
      },
      "source": [
        "---\n",
        "\n",
        "# Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVasAdJYxmZp"
      },
      "source": [
        "!echo \"Change to the JST notation.\"\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Japan /etc/localtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMAZ5ELyxmZp"
      },
      "source": [
        "!echo \"Start mounting your Google Drive.\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!echo \"Move to the working directory.\"\n",
        "%cd 202107_Tool-A/Work600/\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvNuqvC4xmZq"
      },
      "source": [
        "---\n",
        "# 共通準備\n",
        "\n",
        "\"pytorch_advanced\" folder should be ready before you come here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b2qZLfoxmZq"
      },
      "source": [
        "# Skip this if you have already issued git in advance. \n",
        "# If you come here by way of 600-PyTorchADL.ipynb, \n",
        "# you should skip the git command (as you have already issued in 600).  \n",
        "# If you run git when pytorch_advanced already exists, git tells the error and clone won't be made.\n",
        "\n",
        "#!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced\"):\n",
        "    print(\"OK. Alreadly git cloned. You can go.\")\n",
        "else:\n",
        "    print(\"You'd better go back to the first 600-PyTorchADL.ipynb\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGkLljtdxmZq"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcgSKlMxxmZr"
      },
      "source": [
        "%cd \"pytorch_advanced\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um0EwrGSxmZr"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqEb59O9xmZr"
      },
      "source": [
        "%cd \"3_semantic_segmentation\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNqNiyHFxmZr"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rux859mS5dGO"
      },
      "source": [
        "---\n",
        "# VOC2012準備\n",
        "\n",
        "VOCdevkit/ from VOCtrainval_11-May-2012.tar is placed at /root .  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDDBrUtU54KX"
      },
      "source": [
        "# It takes one minute or so.\n",
        "\n",
        "%cd /root\n",
        "!tar xf \"/content/drive/My Drive/202107_Tool-A/Work600/pytorch_advanced/2_objectdetection/data/VOCtrainval_11-May-2012.tar\"\n",
        "!ls /root/VOCdevkit\n",
        "%cd -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpW4WUIqHiy6"
      },
      "source": [
        "# VOC2012のrootpath\n",
        "rootpath = \"/root/VOCdevkit/VOC2012/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBc_SJw4iMKA"
      },
      "source": [
        "---\n",
        "# 事前準備\n",
        "\n",
        "- 学習させた重みパラメータ「pspnet50_30.pth」をフォルダ「weights」に用意してあるものとする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLgiVUeyiMKA"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT9lj4JBiMKB"
      },
      "source": [
        "# ファイルパスリストを用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f27uxkFwiMKB"
      },
      "source": [
        "from utils.dataloader import make_datapath_list, DataTransform\n",
        "\n",
        "\n",
        "# ファイルパスリスト作成\n",
        "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
        "    rootpath=rootpath)\n",
        "\n",
        "# 後ほどアノテーション画像のみを使用する\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvv4euCAiMKB"
      },
      "source": [
        "# ネットワークを用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZCcmVJRiMKC"
      },
      "source": [
        "from utils.pspnet import PSPNet\n",
        "\n",
        "net = PSPNet(n_classes=21)\n",
        "\n",
        "# 学習済みパラメータをロード\n",
        "state_dict = torch.load(\"./weights/pspnet50_30.pth\",\n",
        "                        map_location={'cuda:0': 'cpu'})\n",
        "net.load_state_dict(state_dict)\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードしました')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7aConW_iMKC"
      },
      "source": [
        "# 推論実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "D6dGBe7KiMKD"
      },
      "source": [
        "# Just to surpress UserWarning\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# 1. 元画像の表示\n",
        "image_file_path = \"./data/cowboy-757575_640.jpg\"\n",
        "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
        "img_width, img_height = img.size\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# 2. 前処理クラスの作成\n",
        "color_mean = (0.485, 0.456, 0.406)\n",
        "color_std = (0.229, 0.224, 0.225)\n",
        "transform = DataTransform(\n",
        "    input_size=475, color_mean=color_mean, color_std=color_std)\n",
        "\n",
        "# 3. 前処理\n",
        "# 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
        "anno_file_path = val_anno_list[0]\n",
        "anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
        "p_palette = anno_class_img.getpalette()\n",
        "phase = \"val\"\n",
        "img, anno_class_img = transform(phase, img, anno_class_img)\n",
        "\n",
        "\n",
        "# 4. PSPNetで推論する\n",
        "net.eval()\n",
        "x = img.unsqueeze(0)  # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
        "outputs = net(x)\n",
        "y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
        "\n",
        "\n",
        "# 5. PSPNetの出力から最大クラスを求め、カラーパレット形式にし、画像サイズを元に戻す\n",
        "y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
        "y = np.argmax(y, axis=0)\n",
        "anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
        "anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
        "anno_class_img.putpalette(p_palette)\n",
        "plt.imshow(anno_class_img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 6. 画像を透過させて重ねる\n",
        "trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
        "anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
        "\n",
        "for x in range(img_width):\n",
        "    for y in range(img_height):\n",
        "        # 推論結果画像のピクセルデータを取得\n",
        "        pixel = anno_class_img.getpixel((x, y))\n",
        "        r, g, b, a = pixel\n",
        "\n",
        "        # (0, 0, 0)の背景ならそのままにして透過させる\n",
        "        if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
        "            continue\n",
        "        else:\n",
        "            # それ以外の色は用意した画像にピクセルを書き込む\n",
        "            trans_img.putpixel((x, y), (r, g, b, 150))\n",
        "            # 150は透過度の大きさを指定している\n",
        "\n",
        "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
        "result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
        "plt.imshow(result)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j05r46kuiMKD"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalwdZseikMF"
      },
      "source": [
        "---\n",
        "Revised by KAMEDA, Yoshinari at University of Tsukuba for lecture purpose.  \n",
        "Original: https://github.com/YutaroOgawa/pytorch_advanced\n",
        "\n",
        "2021/08/02. "
      ]
    }
  ]
}