{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "GC6-4_EfficientGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2021/blob/main/600/pytorch_advanced-revised/6_gan_anomaly_detection/GC6_4_EfficientGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZaLsEIeL8J7"
      },
      "source": [
        "# 6.4 Efficient GANの作成\n",
        "\n",
        "- 本ファイルでは、Efficient GANのネットワークを実装し、学習をします。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey6RtLORL8KI"
      },
      "source": [
        "# 6.4 学習目標\n",
        "\n",
        "1.\tEfficient GANを実装し、手書き数字画像で異常検知が生成できる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YQwKbHLu7vN"
      },
      "source": [
        "---\n",
        "#  GANによる異常検知の準備\n",
        "\n",
        "- 第6章で使用するフォルダの作成とファイルのダウンロードを行います。\n",
        "- ※make_folders_and_data_downloads.ipynb の内容を展開したものです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMWPVAcGd3GW"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-eSMwpru7vP"
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUEKP-9_u7vQ"
      },
      "source": [
        "# フォルダ「data」が存在しない場合は作成する\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD48VRUau7vQ"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "# AWSのAMIでsklernのversionが0.20より低い場合はバージョンを更新します\n",
        "# pip install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isjhz44mu7vR"
      },
      "source": [
        "# MNISTの手書き数字画像をダウンロードし読み込みます\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# mnist = fetch_openml('mnist_784', version=1, data_home=\"./data/\")  # data_homeは保存先を指定します\n",
        "mnist = fetch_openml('mnist_784', version=1, data_home=\"./data/\", as_frame=False)  \n",
        "# Issue #153 2020年12月にリリースされたsklearn 0.24.0以降の仕様変更に合わせる場合\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJYcnbVdu7vS"
      },
      "source": [
        "# データの取り出し\n",
        "X = mnist.data\n",
        "y = mnist.target\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZHt7vvZu7vS"
      },
      "source": [
        "# MNISTのデータの1つ目を可視化する\n",
        "plt.imshow(X[0].reshape(28, 28), cmap='gray')\n",
        "print(\"この画像データのラベルは{}です\".format(y[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNO8C28Zu7vT"
      },
      "source": [
        "# フォルダ「data」の下にフォルダ「img_78」を作成する\n",
        "data_dir_path = \"./data/img_78/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW3AIfo-u7vT"
      },
      "source": [
        "# MNISTから数字7、8の画像だけフォルダ「img_78」に画像として保存していく\n",
        "count7=0\n",
        "count8=0\n",
        "max_num=200  # 画像は200枚ずつ作成する\n",
        "\n",
        "for i in range(len(X)):\n",
        "    \n",
        "    # 画像7の作成\n",
        "    if (y[i] is \"7\") and (count7<max_num):\n",
        "        file_path=\"./data/img_78/img_7_\"+str(count7)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28×28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64に拡大\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count7+=1 \n",
        "    \n",
        "    # 画像8の作成\n",
        "    if (y[i] is \"8\") and (count8<max_num):\n",
        "        file_path=\"./data/img_78/img_8_\"+str(count8)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28*28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64に拡大\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count8+=1\n",
        "        \n",
        "    # 7と8を200枚ずつ作成したらbreak\n",
        "    if (count7>=max_num) and (count8>=max_num):\n",
        "        break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcqPDKDmu7vU"
      },
      "source": [
        "# フォルダ「data」の下にフォルダ「test」を作成する\n",
        "data_dir_path = \"./data/test/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWdcYTSfu7vU"
      },
      "source": [
        "# 上記で7,8の画像を作成するのに使用したindexの最終値\n",
        "i_start = i+1\n",
        "print(i_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8U8Tavxu7vV"
      },
      "source": [
        "# MNISTから数字7、8の画像だけフォルダ「img_78」に画像として保存していく\n",
        "count2=0\n",
        "count7=0\n",
        "count8=0\n",
        "max_num=5  # 画像は5枚ずつ作成する\n",
        "\n",
        "for i in range(i_start,len(X)):  # i_startから始める\n",
        "    \n",
        "    # 画像2の作成\n",
        "    if (y[i] is \"2\") and (count2<max_num):\n",
        "        file_path=\"./data/test/img_2_\"+str(count2)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28×28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64に拡大\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count2+=1\n",
        "    \n",
        "    # 画像7の作成\n",
        "    if (y[i] is \"7\") and (count7<max_num):\n",
        "        file_path=\"./data/test/img_7_\"+str(count7)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28×28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64に拡大\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count7+=1 \n",
        "    \n",
        "    # 画像8の作成\n",
        "    if (y[i] is \"8\") and (count8<max_num):\n",
        "        file_path=\"./data/test/img_8_\"+str(count8)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28*28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64に拡大\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count8+=1 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeOBwR31u7vV"
      },
      "source": [
        "# フォルダ「data」の下にフォルダ「img_78_28size」を作成する\n",
        "data_dir_path = \"./data/img_78_28size/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niPi9Mydu7vV"
      },
      "source": [
        "# MNISTから数字7、8の画像だけフォルダ「img_78_28size」に画像として保存していく\n",
        "count7=0\n",
        "count8=0\n",
        "max_num=200  # 画像は200枚ずつ作成する\n",
        "\n",
        "for i in range(len(X)):\n",
        "    \n",
        "    # 画像7の作成\n",
        "    if (y[i] is \"7\") and (count7<max_num):\n",
        "        file_path=\"./data/img_78_28size/img_7_\"+str(count7)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28×28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count7+=1 \n",
        "    \n",
        "    # 画像8の作成\n",
        "    if (y[i] is \"8\") and (count8<max_num):\n",
        "        file_path=\"./data/img_78_28size/img_8_\"+str(count8)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28*28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count8+=1\n",
        "    \n",
        "    if (count7>=max_num) and (count8>=max_num):\n",
        "        break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5Me2CKRu7vW"
      },
      "source": [
        "# フォルダ「data」の下にフォルダ「test」を作成する\n",
        "data_dir_path = \"./data/test_28size/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)\n",
        "\n",
        "# 上記で7,8の画像を作成するのに使用したindexの最終値\n",
        "i_start = i+1\n",
        "print(i_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXjcWUjnu7vW"
      },
      "source": [
        "# MNISTから数字7、8の画像だけフォルダ「img_78」に画像として保存していく\n",
        "count2=0\n",
        "count7=0\n",
        "count8=0\n",
        "max_num=5  # 画像は5枚ずつ作成する\n",
        "\n",
        "for i in range(i_start,len(X)):  # i_startから始める\n",
        "    \n",
        "    # 画像2の作成\n",
        "    if (y[i] is \"2\") and (count2<max_num):\n",
        "        file_path=\"./data/test_28size/img_2_\"+str(count2)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28×28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count2+=1 \n",
        "    \n",
        "    # 画像7の作成\n",
        "    if (y[i] is \"7\") and (count7<max_num):\n",
        "        file_path=\"./data/test_28size/img_7_\"+str(count7)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28×28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count7+=1 \n",
        "    \n",
        "    # 画像8の作成\n",
        "    if (y[i] is \"8\") and (count8<max_num):\n",
        "        file_path=\"./data/test_28size/img_8_\"+str(count8)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  # 画像を28*28の形に変形\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 画像をPILに\n",
        "        pil_img_f.save(file_path)  # 保存\n",
        "        count8+=1 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNnV0rM1L8KK"
      },
      "source": [
        "---\n",
        "# 事前準備\n",
        "書籍の指示に従い、本章で使用するデータを用意します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lGX1rk4L8KL"
      },
      "source": [
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKc25TAjL8KP"
      },
      "source": [
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "torch.cuda.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlfVYAe2L8KR"
      },
      "source": [
        "# Generatorの実装\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68sd3hevL8KS"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(z_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(1024, 7*7*128),\n",
        "            nn.BatchNorm1d(7*7*128),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=64,\n",
        "                               kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.last = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=1,\n",
        "                               kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh())\n",
        "        # 注意：白黒画像なので出力チャネルは1つだけ\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.layer1(z)\n",
        "        out = self.layer2(out)\n",
        "\n",
        "        # 転置畳み込み層に入れるためにテンソルの形を整形\n",
        "        out = out.view(z.shape[0], 128, 7, 7)\n",
        "        out = self.layer3(out)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWygUNjSL8KU"
      },
      "source": [
        "# 動作確認\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "G = Generator(z_dim=20)\n",
        "G.train()\n",
        "\n",
        "# 入力する乱数\n",
        "# バッチノーマライゼーションがあるのでミニバッチ数は2以上\n",
        "input_z = torch.randn(2, 20)\n",
        "\n",
        "# 偽画像を出力\n",
        "fake_images = G(input_z)  # torch.Size([2, 1, 28, 28])\n",
        "img_transformed = fake_images[0][0].detach().numpy()\n",
        "plt.imshow(img_transformed, 'gray')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIyWxLJPL8KW"
      },
      "source": [
        "# Discriminatorの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug0Iof6uL8KX"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # 画像側の入力処理\n",
        "        self.x_layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=4,\n",
        "                      stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "        # 注意：白黒画像なので入力チャネルは1つだけ\n",
        "\n",
        "        self.x_layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=4,\n",
        "                      stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        # 乱数側の入力処理\n",
        "        self.z_layer1 = nn.Linear(z_dim, 512)\n",
        "\n",
        "        # 最後の判定\n",
        "        self.last1 = nn.Sequential(\n",
        "            nn.Linear(3648, 1024),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.last2 = nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, x, z):\n",
        "\n",
        "        # 画像側の入力処理\n",
        "        x_out = self.x_layer1(x)\n",
        "        x_out = self.x_layer2(x_out)\n",
        "\n",
        "        # 乱数側の入力処理\n",
        "        z = z.view(z.shape[0], -1)\n",
        "        z_out = self.z_layer1(z)\n",
        "\n",
        "        # x_outとz_outを結合し、全結合層で判定\n",
        "        x_out = x_out.view(-1, 64 * 7 * 7)\n",
        "        out = torch.cat([x_out, z_out], dim=1)\n",
        "        out = self.last1(out)\n",
        "\n",
        "        feature = out  # 最後にチャネルを1つに集約する手前の情報\n",
        "        feature = feature.view(feature.size()[0], -1)  # 2次元に変換\n",
        "\n",
        "        out = self.last2(out)\n",
        "\n",
        "        return out, feature\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsKNLk4BL8Ka"
      },
      "source": [
        "# 動作確認\n",
        "D = Discriminator(z_dim=20)\n",
        "\n",
        "# 偽画像を生成\n",
        "input_z = torch.randn(2, 20)\n",
        "fake_images = G(input_z)\n",
        "\n",
        "# 偽画像をDに入力\n",
        "d_out, _ = D(fake_images, input_z)\n",
        "\n",
        "# 出力d_outにSigmoidをかけて0から1に変換\n",
        "print(nn.Sigmoid()(d_out))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlRmvebQL8Kd"
      },
      "source": [
        "# Encoderの実装\n",
        "\n",
        "画像をzに変換する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih6gWabsL8Kd"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3,\n",
        "                      stride=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "        # 注意：白黒画像なので入力チャネルは1つだけ\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3,\n",
        "                      stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3,\n",
        "                      stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        # ここまでで画像のサイズは7×7になっている\n",
        "        self.last = nn.Linear(128 * 7 * 7, z_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        # FCに入れるためにテンソルの形を整形\n",
        "        out = out.view(-1, 128 * 7 * 7)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vun_KvShL8Kh"
      },
      "source": [
        "# 動作確認\n",
        "E = Encoder(z_dim=20)\n",
        "\n",
        "# 入力する画像データ\n",
        "x = fake_images  # fake_imagesは上のGで作成したもの\n",
        "\n",
        "# 画像からzをEncode\n",
        "z = E(x)\n",
        "\n",
        "print(z.shape)\n",
        "print(z)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnwXk0a-L8Kl"
      },
      "source": [
        "# DataLoaderの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lXhlnQKL8Kl"
      },
      "source": [
        "def make_datapath_list():\n",
        "    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n",
        "\n",
        "    train_img_list = list()  # 画像ファイルパスを格納\n",
        "\n",
        "    for img_idx in range(200):\n",
        "        img_path = \"./data/img_78_28size/img_7_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "        img_path = \"./data/img_78_28size/img_8_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "    return train_img_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffLPO9nJL8Kn"
      },
      "source": [
        "class ImageTransform():\n",
        "    \"\"\"画像の前処理クラス\"\"\"\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        self.data_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.data_transform(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc4oS_UML8Kq"
      },
      "source": [
        "class GAN_Img_Dataset(data.Dataset):\n",
        "    \"\"\"画像のDatasetクラス。PyTorchのDatasetクラスを継承\"\"\"\n",
        "\n",
        "    def __init__(self, file_list, transform):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        '''画像の枚数を返す'''\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''前処理をした画像のTensor形式のデータを取得'''\n",
        "\n",
        "        img_path = self.file_list[index]\n",
        "        img = Image.open(img_path)  # [高さ][幅]白黒\n",
        "\n",
        "        # 画像の前処理\n",
        "        img_transformed = self.transform(img)\n",
        "\n",
        "        return img_transformed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfBEgPZUL8Ks"
      },
      "source": [
        "# DataLoaderの作成と動作確認\n",
        "\n",
        "# ファイルリストを作成\n",
        "train_img_list=make_datapath_list()\n",
        "\n",
        "# Datasetを作成\n",
        "mean = (0.5,)\n",
        "std = (0.5,)\n",
        "train_dataset = GAN_Img_Dataset(\n",
        "    file_list=train_img_list, transform=ImageTransform(mean, std))\n",
        "\n",
        "# DataLoaderを作成\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 動作の確認\n",
        "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
        "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
        "print(imges.size())  # torch.Size([64, 1, 64, 64])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9vLW5T6L8Ku"
      },
      "source": [
        "# 学習させる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8yHVN7EjDkJ"
      },
      "source": [
        "(See the [Issue 144](https://github.com/YutaroOgawa/pytorch_advanced/issues/144) for the revision in the next code cell.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDF9_QozL8Kv"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(G, D, E, dataloader, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # 最適化手法の設定\n",
        "    lr_ge = 0.0001\n",
        "    lr_d = 0.0001/4\n",
        "    beta1, beta2 = 0.5, 0.999\n",
        "    g_optimizer = torch.optim.Adam(G.parameters(), lr_ge, [beta1, beta2])\n",
        "    e_optimizer = torch.optim.Adam(E.parameters(), lr_ge, [beta1, beta2])\n",
        "    d_optimizer = torch.optim.Adam(D.parameters(), lr_d, [beta1, beta2])\n",
        "\n",
        "    # 誤差関数を定義\n",
        "    # BCEWithLogitsLossは入力にシグモイド（logit）をかけてから、\n",
        "    # バイナリークロスエントロピーを計算\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "    # パラメータをハードコーディング\n",
        "    z_dim = 20\n",
        "    mini_batch_size = 64\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    G.to(device)\n",
        "    E.to(device)\n",
        "    D.to(device)\n",
        "\n",
        "    G.train()  # モデルを訓練モードに\n",
        "    E.train()  # モデルを訓練モードに\n",
        "    D.train()  # モデルを訓練モードに\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # 画像の枚数\n",
        "    num_train_imgs = len(dataloader.dataset)\n",
        "    batch_size = dataloader.batch_size\n",
        "\n",
        "    # イテレーションカウンタをセット\n",
        "    iteration = 1\n",
        "    logs = []\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # 開始時刻を保存\n",
        "        t_epoch_start = time.time()\n",
        "        epoch_g_loss = 0.0  # epochの損失和\n",
        "        epoch_e_loss = 0.0  # epochの損失和\n",
        "        epoch_d_loss = 0.0  # epochの損失和\n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-------------')\n",
        "        print('（train）')\n",
        "\n",
        "        # データローダーからminibatchずつ取り出すループ\n",
        "        for imges in dataloader:\n",
        "\n",
        "            # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
        "            if imges.size()[0] == 1:\n",
        "                continue\n",
        "\n",
        "            # ミニバッチサイズの1もしくは0のラベル役のテンソルを作成\n",
        "            # 正解ラベルと偽ラベルを作成\n",
        "            # epochの最後のイテレーションはミニバッチの数が少なくなる\n",
        "            mini_batch_size = imges.size()[0]\n",
        "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
        "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
        "\n",
        "            # GPUが使えるならGPUにデータを送る\n",
        "            imges = imges.to(device)\n",
        "\n",
        "            # --------------------\n",
        "            # 1. Discriminatorの学習\n",
        "            # --------------------\n",
        "            # 真の画像を判定　\n",
        "            z_out_real = E(imges)\n",
        "            d_out_real, _ = D(imges, z_out_real)\n",
        "\n",
        "            # 偽の画像を生成して判定\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
        "            fake_images = G(input_z)\n",
        "            d_out_fake, _ = D(fake_images, input_z)\n",
        "\n",
        "            # 誤差を計算\n",
        "            # Revised by Issue 144\n",
        "            label_real = label_real.type_as(d_out_real.view(-1))\n",
        "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
        "            label_fake = label_fake.type_as(d_out_fake.view(-1))\n",
        "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "            # バックプロパゲーション\n",
        "            d_optimizer.zero_grad()\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # --------------------\n",
        "            # 2. Generatorの学習\n",
        "            # --------------------\n",
        "            # 偽の画像を生成して判定\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
        "            fake_images = G(input_z)\n",
        "            d_out_fake, _ = D(fake_images, input_z)\n",
        "\n",
        "            # 誤差を計算\n",
        "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
        "\n",
        "            # バックプロパゲーション\n",
        "            g_optimizer.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            # --------------------\n",
        "            # 3. Encoderの学習\n",
        "            # --------------------\n",
        "            # 真の画像のzを推定\n",
        "            z_out_real = E(imges)\n",
        "            d_out_real, _ = D(imges, z_out_real)\n",
        "\n",
        "            # 誤差を計算\n",
        "            e_loss = criterion(d_out_real.view(-1), label_fake)\n",
        "\n",
        "            # バックプロパゲーション\n",
        "            e_optimizer.zero_grad()\n",
        "            e_loss.backward()\n",
        "            e_optimizer.step()\n",
        "\n",
        "            # --------------------\n",
        "            # 4. 記録\n",
        "            # --------------------\n",
        "            epoch_d_loss += d_loss.item()\n",
        "            epoch_g_loss += g_loss.item()\n",
        "            epoch_e_loss += e_loss.item()\n",
        "            iteration += 1\n",
        "\n",
        "        # epochのphaseごとのlossと正解率\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f} ||Epoch_E_Loss:{:.4f}'.format(\n",
        "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size, epoch_e_loss/batch_size))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "    print(\"総イテレーション回数:\", iteration)\n",
        "\n",
        "    return G, D, E\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o7-C9d7L8Kz"
      },
      "source": [
        "# ネットワークの初期化\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        # conv2dとConvTranspose2dの初期化\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        # BatchNorm2dの初期化\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        # 全結合層Linearの初期化\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "# 初期化の実施\n",
        "G.apply(weights_init)\n",
        "E.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "\n",
        "print(\"ネットワークの初期化完了\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-eQCLPJL8K1"
      },
      "source": [
        "# 学習・検証を実行する\n",
        "# 6分ほどかかる (GC with GPU)\n",
        "num_epochs = 1500\n",
        "G_update, D_update, E_update = train_model(\n",
        "    G, D, E, dataloader=train_dataloader, num_epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL_pxhfEL8K5"
      },
      "source": [
        "# 生成画像と訓練データを可視化する\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 入力の乱数生成\n",
        "batch_size = 8\n",
        "z_dim = 20\n",
        "fixed_z = torch.randn(batch_size, z_dim)\n",
        "G_update.eval()\n",
        "fake_images = G_update(fixed_z.to(device))\n",
        "\n",
        "# 訓練データ\n",
        "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
        "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
        "\n",
        "\n",
        "# 出力\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "for i in range(0, 5):\n",
        "    # 上段に訓練データを\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
        "\n",
        "    # 下段に生成データを表示する\n",
        "    plt.subplot(2, 5, 5+i+1)\n",
        "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKa9G-CZL8K7"
      },
      "source": [
        "# テスト画像で異常検知する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcB7w-4xL8K8"
      },
      "source": [
        "# テスト用のDataLoaderの作成\n",
        "\n",
        "\n",
        "def make_test_datapath_list():\n",
        "    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n",
        "\n",
        "    train_img_list = list()  # 画像ファイルパスを格納\n",
        "\n",
        "    for img_idx in range(5):\n",
        "        img_path = \"./data/test_28size/img_7_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "        img_path = \"./data/test_28size/img_8_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "        img_path = \"./data/test_28size/img_2_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "    return train_img_list\n",
        "\n",
        "\n",
        "# ファイルリストを作成\n",
        "test_img_list = make_test_datapath_list()\n",
        "\n",
        "# Datasetを作成\n",
        "mean = (0.5,)\n",
        "std = (0.5,)\n",
        "test_dataset = GAN_Img_Dataset(\n",
        "    file_list=test_img_list, transform=ImageTransform(mean, std))\n",
        "\n",
        "# DataLoaderを作成\n",
        "batch_size = 5\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ua6uY7_L8K-"
      },
      "source": [
        "# テストデータの確認\n",
        "batch_iterator = iter(test_dataloader)  # イテレータに変換\n",
        "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
        "\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "for i in range(0, 5):\n",
        "    # 上段に訓練データを\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB-bso3WL8LB"
      },
      "source": [
        "def Anomaly_score(x, fake_img, z_out_real, D, Lambda=0.1):\n",
        "\n",
        "    # テスト画像xと生成画像fake_imgのピクセルレベルの差の絶対値を求めて、ミニバッチごとに和を求める\n",
        "    residual_loss = torch.abs(x-fake_img)\n",
        "    residual_loss = residual_loss.view(residual_loss.size()[0], -1)\n",
        "    residual_loss = torch.sum(residual_loss, dim=1)\n",
        "\n",
        "    # テスト画像xと生成画像fake_imgを識別器Dに入力し、特徴量マップを取り出す\n",
        "\n",
        "    _, x_feature = D(x, z_out_real)\n",
        "    _, G_feature = D(fake_img, z_out_real)\n",
        "\n",
        "    # テスト画像xと生成画像fake_imgの特徴量の差の絶対値を求めて、ミニバッチごとに和を求める\n",
        "    discrimination_loss = torch.abs(x_feature-G_feature)\n",
        "    discrimination_loss = discrimination_loss.view(\n",
        "        discrimination_loss.size()[0], -1)\n",
        "    discrimination_loss = torch.sum(discrimination_loss, dim=1)\n",
        "\n",
        "    # ミニバッチごとに2種類の損失を足し算する\n",
        "    loss_each = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
        "\n",
        "    # ミニバッチ全部の損失を求める\n",
        "    total_loss = torch.sum(loss_each)\n",
        "\n",
        "    return total_loss, loss_each, residual_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl7OER2yL8LD"
      },
      "source": [
        "# 異常検知したい画像\n",
        "x = imges[0:5]\n",
        "x = x.to(device)\n",
        "\n",
        "# 教師データの画像をエンコードしてzにしてから、Gで生成\n",
        "E_update.eval()\n",
        "G_update.eval()\n",
        "z_out_real = E_update(imges.to(device))\n",
        "imges_reconstract = G_update(z_out_real)\n",
        "\n",
        "# 損失を求める\n",
        "loss, loss_each, residual_loss_each = Anomaly_score(\n",
        "    x, imges_reconstract, z_out_real, D_update, Lambda=0.1)\n",
        "\n",
        "# 損失の計算。トータルの損失\n",
        "loss_each = loss_each.cpu().detach().numpy()\n",
        "print(\"total loss：\", np.round(loss_each, 0))\n",
        "\n",
        "# 画像を可視化\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "for i in range(0, 5):\n",
        "    # 上段に訓練データを\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
        "\n",
        "    # 下段に生成データを表示する\n",
        "    plt.subplot(2, 5, 5+i+1)\n",
        "    plt.imshow(imges_reconstract[i][0].cpu().detach().numpy(), 'gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPOfqd1VL8LE"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYkyl6cog5go"
      },
      "source": [
        "---\n",
        "Revised by KAMEDA, Yoshinari at University of Tsukuba for lecture purpose.  \n",
        "Original: https://github.com/YutaroOgawa/pytorch_advanced\n",
        "\n",
        "2021/08/03. "
      ]
    }
  ]
}