{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2022/blob/main/600/pytorch_advanced-revised/8_nlp_sentiment_bert/GC8_4_bert_IMDb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoycL_XoT5tk"
      },
      "source": [
        "# 8.4 BERTを用いたレビュー文章に対する感情分析モデルの実装と学習・推論\n",
        "\n",
        "本ファイルでは、BERTを使用し、IMDbデータのポジ・ネガを分類するモデルを学習させ、推論します。また推論時のSelf-Attentionを可視化します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcWZ5xD-T5tm"
      },
      "source": [
        "※　本章のファイルはすべて Google Colaboratory (Ubuntu) での動作を前提としています。Windowsなど文字コードが違う環境での動作にはご注意下さい。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC-LAXWET5tn"
      },
      "source": [
        "# 8.4 学習目標\n",
        "\n",
        "1.\tBERTのボキャブラリーをtorchtextで使用する実装方法を理解する\n",
        "2.\tBERTに分類タスク用のアダプターモジュールを追加し、感情分析を実施するモデルを実装できる\n",
        "3.\tBERTをファインチューニングして、モデルを学習できる\n",
        "4.  BERTのSelf-Attentionの重みを可視化し、推論の説明を試みることができる\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z2iYK_ox7s-"
      },
      "source": [
        "---\n",
        "\n",
        "# Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p12QTDHEx7tH",
        "outputId": "087a9496-0915-4b5a-9fdf-88493a0ca371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Change to the JST notation.\n"
          ]
        }
      ],
      "source": [
        "!echo \"Change to the JST notation.\"\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Japan /etc/localtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usdzzcLbx7tI",
        "outputId": "4d0b7746-8770-49bc-da27-059b9e798416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start mounting your Google Drive.\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n",
            "Move to the working directory.\n",
            "/content/drive/My Drive/IMIS_Tool-A/Work600\n",
            "total 4\n",
            "drwx------ 2 root root 4096 Aug  7 22:01 pytorch_advanced\n"
          ]
        }
      ],
      "source": [
        "!echo \"Start mounting your Google Drive.\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!echo \"Move to the working directory.\"\n",
        "%cd IMIS_Tool-A/Work600/\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDc3dnE_x7tJ"
      },
      "source": [
        "---\n",
        "# 共通準備\n",
        "\n",
        "\"pytorch_advanced\" folder should be ready before you come here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cED0rxM7x7tJ",
        "outputId": "793d1679-8ed1-45d6-d8f4-80e5b95afe51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK. Alreadly git cloned. You can go.\n"
          ]
        }
      ],
      "source": [
        "# Skip this if you have already issued git in advance. \n",
        "# If you come here by way of 600-PyTorchADL.ipynb, \n",
        "# you should skip the git command (as you have already issued in 600).  \n",
        "# If you run git when pytorch_advanced already exists, git tells the error and clone won't be made.\n",
        "\n",
        "#!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced\"):\n",
        "    print(\"OK. Alreadly git cloned. You can go.\")\n",
        "else:\n",
        "    print(\"You'd better go back to the first 600-PyTorchADL.ipynb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRia6DwFx7tJ",
        "outputId": "843b700a-e8af-46a5-9338-27f4557660bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pytorch_advanced\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGd5BWZZx7tJ",
        "outputId": "3c090fd5-720a-48b2-bea1-5f5b7970f483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced\n"
          ]
        }
      ],
      "source": [
        "%cd \"pytorch_advanced\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWF4QMix7tK",
        "outputId": "7fe136e0-bb97-46ba-f13a-cd9e4a43f285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1_image_classification\t 7_nlp_sentiment_transformer\n",
            "2_objectdetection\t 8_nlp_sentiment_bert\n",
            "3_semantic_segmentation  9_video_classification_eco\n",
            "4_pose_estimation\t etc\n",
            "5_gan_generation\t LICENSE\n",
            "6_gan_anomaly_detection  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YelRffxx7tK",
        "outputId": "aede43c7-249e-4d4e-ab14-a5c8ced6f057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IMIS_Tool-A/Work600/pytorch_advanced/8_nlp_sentiment_bert\n"
          ]
        }
      ],
      "source": [
        "%cd \"8_nlp_sentiment_bert\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRZz7hVLx7tK",
        "outputId": "d22bb6ce-4875-4dad-b6e7-5b72d342d484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8-2-3_bert_base.ipynb  data\t\t\t\t      utils  weights\n",
            "8-4_bert_IMDb.ipynb    make_folders_and_data_downloads.ipynb  vocab\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0mbX2L9YqiQ"
      },
      "source": [
        "---\n",
        "# 事前準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmhkHYmhYyDk",
        "outputId": "80617739-1ac3-4a53-eccc-8c3a4839582e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 32450685 Aug  9 03:19 ../7_nlp_sentiment_transformer/data/IMDb_test.tsv\n",
            "-rw------- 1 root root 33232823 Aug  9 03:19 ../7_nlp_sentiment_transformer/data/IMDb_train.tsv\n",
            "total 1\n",
            "lrw------- 1 root root 24 Aug  9 03:46 IMDb_test.tsv -> /root/data/IMDb_test.tsv\n",
            "lrw------- 1 root root 25 Aug  9 03:46 IMDb_train.tsv -> /root/data/IMDb_train.tsv\n"
          ]
        }
      ],
      "source": [
        "# porting from 7_nlp_sentiment_transformer\n",
        "!ls -l ../7_nlp_sentiment_transformer/data/IMDb_train.tsv ../7_nlp_sentiment_transformer/data/IMDb_test.tsv\n",
        "!rm -rf   /root/data/\n",
        "!mkdir -p /root/data/\n",
        "!cp ../7_nlp_sentiment_transformer/data/IMDb_train.tsv ../7_nlp_sentiment_transformer/data/IMDb_test.tsv /root/data/\n",
        "!rm -f ./data/IMDb_train.tsv ./data/IMDb_test.tsv\n",
        "!ln -s /root/data/IMDb_train.tsv ./data/\n",
        "!ln -s /root/data/IMDb_test.tsv ./data/\n",
        "!ls -l ./data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKYTZpcShqkV",
        "outputId": "f207772a-39fa-4368-a99a-16634e0b76ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torchtext 0.13.0\n",
            "Uninstalling torchtext-0.13.0:\n",
            "  Successfully uninstalled torchtext-0.13.0\n",
            "Found existing installation: torchvision 0.13.0+cu113\n",
            "Uninstalling torchvision-0.13.0+cu113:\n",
            "  Successfully uninstalled torchvision-0.13.0+cu113\n",
            "Found existing installation: torchaudio 0.12.0+cu113\n",
            "Uninstalling torchaudio-0.12.0+cu113:\n",
            "  Successfully uninstalled torchaudio-0.12.0+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.2 MB/s eta 0:04:20tcmalloc: large alloc 1147494400 bytes == 0x3a560000 @  0x7f605483d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.2 MB/s eta 0:01:25tcmalloc: large alloc 1434370048 bytes == 0x7ebb6000 @  0x7f605483d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0xd43a2000 @  0x7f605483d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, which is not installed.\u001b[0m\n",
            "Successfully installed torch-1.7.1+cu110\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (1.7.1+cu110)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ],
      "source": [
        "# We use torchtext version 0.8 (and torch 1.7.1) that was popular when the book was published. See issue 148.\n",
        "# https://github.com/YutaroOgawa/pytorch_advanced/issues/148\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "!pip uninstall -y torchtext torchvision torchaudio\n",
        "!pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchtext==0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV6o65ZiT5tn"
      },
      "source": [
        "---\n",
        "# 8.4 節\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO55-TCiV2U1",
        "outputId": "34e7b0f9-5df2-4850-e14f-1b78463ea6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n",
            "Installing collected packages: attrdict\n",
            "Successfully installed attrdict-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install attrdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdYNqp9cT5to"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch \n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRsM0wJ7T5to"
      },
      "outputs": [],
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOwCOqDhT5to"
      },
      "source": [
        "# IMDbデータを読み込み\n",
        "\n",
        "* Very similar to 「2.前処理と単語分割の関数を定義」 in [GC7-5_IMDb_Dataset_DataLoader.ipynb](https://github.com/kameda-yoshinari/IMISToolExeA2021/blob/main/600/pytorch_advanced-revised/7_nlp_sentiment_transformer/GC7_5_IMDb_Dataset_DataLoader.ipynb)\n",
        "* BERTのTokenizerを使用\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkY6kQm5T5tp"
      },
      "outputs": [],
      "source": [
        "# 前処理と単語分割をまとめた関数を作成\n",
        "import re\n",
        "import string\n",
        "from utils.bert import BertTokenizer\n",
        "# フォルダ「utils」のbert.pyより\n",
        "\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    '''IMDbの前処理'''\n",
        "    # 改行コードを消去\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    # カンマ、ピリオド以外の記号をスペースに置換\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    # ピリオドなどの前後にはスペースを入れておく\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "\n",
        "# 単語分割用のTokenizerを用意\n",
        "tokenizer_bert = BertTokenizer(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "\n",
        "# 前処理と単語分割をまとめた関数を定義\n",
        "# 単語分割の関数を渡すので、tokenizer_bertではなく、tokenizer_bert.tokenizeを渡す点に注意\n",
        "def tokenizer_with_preprocessing(text, tokenizer=tokenizer_bert.tokenize):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer(text)  # tokenizer_bert\n",
        "    return ret\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP4uRgqtXCyl"
      },
      "source": [
        "# DataLoaderの作成\n",
        "\n",
        "* Very similar to 「DataLoaderの作成」 in [GC7-5_IMDb_Dataset_DataLoader.ipynb](https://github.com/kameda-yoshinari/IMISToolExeA2021/blob/main/600/pytorch_advanced-revised/7_nlp_sentiment_transformer/GC7_5_IMDb_Dataset_DataLoader.ipynb)\n",
        "* BERTのTokenizerを使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Syb7wXxiT5tp"
      },
      "outputs": [],
      "source": [
        "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "# https://github.com/YutaroOgawa/pytorch_advanced/issues/148\n",
        "max_length = 256\n",
        "\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"[CLS]\", eos_token=\"[SEP]\", pad_token='[PAD]', unk_token='[UNK]')\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# (注釈)：各引数を再確認\n",
        "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
        "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
        "# use_vocab：単語をボキャブラリーに追加するかどうか\n",
        "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
        "# include_length: 文章の単語数のデータを保持するか\n",
        "# batch_first：ミニバッチの次元を先頭に用意するかどうか\n",
        "# fix_length：全部の文章を指定した長さと同じになるように、paddingします\n",
        "# init_token, eos_token, pad_token, unk_token：文頭、文末、padding、未知語に対して、どんな単語を与えるかを指定\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyYzn5waT5tq"
      },
      "outputs": [],
      "source": [
        "# フォルダ「data」から各tsvファイルを読み込みます\n",
        "# BERT用で処理するので、時間がかかります\n",
        "# I takes 3 minutes or os on GC\n",
        "# https://github.com/YutaroOgawa/pytorch_advanced/issues/148\n",
        "\n",
        "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='./data/', train='IMDb_train.tsv',\n",
        "    test='IMDb_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "# torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\n",
        "train_ds, val_ds = train_val_ds.split(\n",
        "    split_ratio=0.8, random_state=random.seed(1234))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY_j_Q7tX1Q8"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zARRiwoOT5tq"
      },
      "outputs": [],
      "source": [
        "# BERTはBERTが持つ全単語でBertEmbeddingモジュールを作成しているので、ボキャブラリーとしては全単語を使用します\n",
        "# そのため訓練データからボキャブラリーは作成しません\n",
        "\n",
        "# まずBERT用の単語辞書を辞書型変数に用意します\n",
        "from utils.bert import BertTokenizer, load_vocab\n",
        "\n",
        "vocab_bert, ids_to_tokens_bert = load_vocab(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\")\n",
        "\n",
        "\n",
        "# このまま、TEXT.vocab.stoi= vocab_bert (stoiはstring_to_IDで、単語からIDへの辞書)としたいですが、\n",
        "# 一度bulild_vocabを実行しないとTEXTオブジェクトがvocabのメンバ変数をもってくれないです。\n",
        "# （'Field' object has no attribute 'vocab' というエラーをはきます）\n",
        "\n",
        "# 1度適当にbuild_vocabでボキャブラリーを作成してから、BERTのボキャブラリーを上書きします\n",
        "TEXT.build_vocab(train_ds, min_freq=1)\n",
        "TEXT.vocab.stoi = vocab_bert\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bTdgyTzT5tq"
      },
      "outputs": [],
      "source": [
        "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "batch_size = 32  # BERTでは16、32あたりを使用する\n",
        "# https://github.com/YutaroOgawa/pytorch_advanced/issues/148\n",
        "\n",
        "train_dl = torchtext.data.Iterator(\n",
        "    train_ds, batch_size=batch_size, train=True)\n",
        "\n",
        "val_dl = torchtext.data.Iterator(\n",
        "    val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "test_dl = torchtext.data.Iterator(\n",
        "    test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip1hTmD4T5tr",
        "outputId": "0f043003-bfef-4ef2-93c6-fedcee57f8b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[  101,  2045,  2347,  ...,  2660,  3531,   102],\n",
            "        [  101,  2019,  2137,  ...,  1055,  2801,   102],\n",
            "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2061,  1045,  ...,     0,     0,     0],\n",
            "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
            "        [  101,  2040,  2758,  ...,  1999, 10866,   102]]), tensor([256, 256, 153, 167, 140, 196, 178, 256, 188, 180, 100, 256, 218, 169,\n",
            "        140, 256, 120, 134,  79, 256, 256, 253, 154, 242, 122, 163, 202, 163,\n",
            "        167, 242,  93, 256]))\n",
            "tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
            "        0, 1, 1, 1, 0, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# 動作確認 検証データのデータセットで確認\n",
        "batch = next(iter(val_dl))\n",
        "print(batch.Text)\n",
        "print(batch.Label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvM588pwT5tr",
        "outputId": "c8959b62-89cd-4e1f-8f0a-3d255f009f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'an', 'american', 'in', 'paris', 'is', 'an', 'integrated', 'musical', ',', 'meaning', 'that', 'the', 'songs', 'and', 'dances', 'blend', 'perfectly', 'with', 'the', 'story', '.', 'the', 'film', 'was', 'inspired', 'by', 'the', '1928', 'orchestral', 'composition', 'by', 'george', 'gershwin', '.', 'the', 'story', 'of', 'the', 'film', 'is', 'interspersed', 'with', 'show', 'stopping', 'dance', 'numbers', 'choreographed', 'by', 'gene', 'kelly', 'and', 'set', 'to', 'popular', 'gershwin', 'tunes', '.', 'songs', 'and', 'music', 'include', 'i', 'got', 'rhythm', ',', 's', 'wonderful', ',', 'and', 'our', 'love', 'is', 'here', 'to', 'stay', '.', 'it', 'set', 'a', 'new', 'standard', 'for', 'the', 'sub', '##gen', '##re', 'known', 'as', 'the', 'song', '##book', 'musical', 'with', 'dozens', 'of', 'gershwin', 'tunes', 'buried', 'in', 'the', 'under', '##sco', '##re', '.', 'the', 'climax', 'is', 'the', 'american', 'in', 'paris', 'ballet', ',', 'an', '18', 'minute', 'dance', 'featuring', 'kelly', 'and', 'car', '##on', 'set', 'to', 'gershwin', 's', 'an', 'american', 'in', 'paris', ',', 'featuring', 'an', 'impression', '##istic', 'period', 'day', '##dre', '##am', 'in', 'the', 'style', 'of', 'various', 'painters', ',', 'is', 'one', 'of', 'the', 'longest', 'un', '##int', '##er', '##rup', '##ted', 'dance', 'sequences', 'of', 'any', 'hollywood', 'film', '.', 'the', 'ballet', 'alone', 'cost', 'more', 'than', 'half', 'a', 'million', 'dollars', ',', 'a', 'staggering', 'sum', 'at', 'the', 'time', '.', 'it', 's', 'funny', 'to', 'think', 'of', 'such', 'a', 'work', 'of', 'art', 'being', 'born', 'over', 'a', 'pool', 'game', 'between', 'film', 'producer', 'arthur', 'freed', 'sing', '##in', 'in', 'the', 'rain', ',', 'wizard', 'of', 'oz', ',', 'on', 'the', 'town', ',', 'meet', 'me', 'in', 'st', '.', 'louis', 'and', 'the', 'band', 'wagon', 'and', 'ira', 'gershwin', '.', 'it', 'was', 'freed', 's', 'idea', 'to', 'buy', 'the', 'title', 'so', 'he', 'could', 'use', 'if', 'in', 'a', 'film', 'about', 'paris', 'and', 'gershwin', 's', 'idea', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# ミニバッチの1文目を確認してみる\n",
        "text_minibatch_1 = (batch.Text[0][1]).numpy()\n",
        "\n",
        "# IDを単語に戻す\n",
        "text = tokenizer_bert.convert_ids_to_tokens(text_minibatch_1)\n",
        "\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqAy6qiOT5ts"
      },
      "source": [
        "# 感情分析用のBERTモデルを構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlGcl6wFT5ts",
        "outputId": "2c1410c6-3f62-4407-9cd2-ed4a19ccb5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight→pooler.dense.weight\n",
            "bert.pooler.dense.bias→pooler.dense.bias\n"
          ]
        }
      ],
      "source": [
        "from utils.bert import get_config, BertModel, set_learned_params\n",
        "\n",
        "# モデル設定のJOSNファイルをオブジェクト変数として読み込みます\n",
        "config = get_config(file_path=\"./weights/bert_config.json\")\n",
        "\n",
        "# BERTモデルを作成します\n",
        "net_bert = BertModel(config)\n",
        "\n",
        "# BERTモデルに学習済みパラメータセットします\n",
        "net_bert = set_learned_params(\n",
        "    net_bert, weights_path=\"./weights/pytorch_model.bin\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYRzZZ5iT5ts"
      },
      "outputs": [],
      "source": [
        "class BertForIMDb(nn.Module):\n",
        "    '''BERTモデルにIMDbのポジ・ネガを判定する部分をつなげたモデル'''\n",
        "\n",
        "    def __init__(self, net_bert):\n",
        "        super(BertForIMDb, self).__init__()\n",
        "\n",
        "        # BERTモジュール\n",
        "        self.bert = net_bert  # BERTモデル\n",
        "\n",
        "        # headにポジネガ予測を追加\n",
        "        # 入力はBERTの出力特徴量の次元、出力はポジ・ネガの2つ\n",
        "        self.cls = nn.Linear(in_features=768, out_features=2)\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.cls.weight, std=0.02)\n",
        "        nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_flg=False):\n",
        "        '''\n",
        "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
        "        token_type_ids： [batch_size, sequence_length]の、各単語が1文目なのか、2文目なのかを示すid\n",
        "        attention_mask：Transformerのマスクと同じ働きのマスキングです\n",
        "        output_all_encoded_layers：最終出力に12段のTransformerの全部をリストで返すか、最後だけかを指定\n",
        "        attention_show_flg：Self-Attentionの重みを返すかのフラグ\n",
        "        '''\n",
        "\n",
        "        # BERTの基本モデル部分の順伝搬\n",
        "        # 順伝搬させる\n",
        "        if attention_show_flg == True:\n",
        "            '''attention_showのときは、attention_probsもリターンする'''\n",
        "            encoded_layers, pooled_output, attention_probs = self.bert(\n",
        "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "        elif attention_show_flg == False:\n",
        "            encoded_layers, pooled_output = self.bert(\n",
        "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "\n",
        "        # 入力文章の1単語目[CLS]の特徴量を使用して、ポジ・ネガを分類します\n",
        "        vec_0 = encoded_layers[:, 0, :]\n",
        "        vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_sizeに変換\n",
        "        out = self.cls(vec_0)\n",
        "\n",
        "        # attention_showのときは、attention_probs（1番最後の）もリターンする\n",
        "        if attention_show_flg == True:\n",
        "            return out, attention_probs\n",
        "        elif attention_show_flg == False:\n",
        "            return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmTzj7l0T5tt",
        "outputId": "bcf2c76e-4ab2-4905-9fb2-ee1bf57f4a09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ネットワーク設定完了\n"
          ]
        }
      ],
      "source": [
        "# モデル構築\n",
        "net = BertForIMDb(net_bert)\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_lA-uJGT5tt"
      },
      "source": [
        "# BERTのファインチューニングに向けた設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCXBVg4GT5tt"
      },
      "outputs": [],
      "source": [
        "# 勾配計算を最後のBertLayerモジュールと追加した分類アダプターのみ実行\n",
        "\n",
        "# 1. まず全部を、勾配計算Falseにしてしまう\n",
        "for name, param in net.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. 最後のBertLayerモジュールを勾配計算ありに変更\n",
        "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. 識別器を勾配計算ありに変更\n",
        "for name, param in net.cls.named_parameters():\n",
        "    param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EUgfs-wT5tt"
      },
      "outputs": [],
      "source": [
        "# 最適化手法の設定\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "    {'params': net.cls.parameters(), 'lr': 5e-5}\n",
        "], betas=(0.9, 0.999))\n",
        "\n",
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOyKW7ZLT5tu"
      },
      "source": [
        "# 学習・検証を実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQiGcYvYT5tu"
      },
      "outputs": [],
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "            iteration = 1\n",
        "\n",
        "            # 開始時刻を保存\n",
        "            t_epoch_start = time.time()\n",
        "            t_iter_start = time.time()\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.Text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BertForIMDbに入力\n",
        "                    outputs = net(inputs, token_type_ids=None, attention_mask=None,\n",
        "                                  output_all_encoded_layers=False, attention_show_flg=False)\n",
        "\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            t_iter_finish = time.time()\n",
        "                            duration = t_iter_finish - t_iter_start\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec. || 本イテレーションの正解率：{}'.format(\n",
        "                                iteration, loss.item(), duration, acc))\n",
        "                            t_iter_start = time.time()\n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            t_epoch_finish = time.time()\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "            t_epoch_start = time.time()\n",
        "\n",
        "    return net\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qZ-pXTET5tu",
        "outputId": "5ffc2645-900e-4e33-d47c-584c068bfa3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "イテレーション 10 || Loss: 0.7453 || 10iter: 5.2818 sec. || 本イテレーションの正解率：0.46875\n",
            "イテレーション 20 || Loss: 0.6239 || 10iter: 5.1801 sec. || 本イテレーションの正解率：0.71875\n",
            "イテレーション 30 || Loss: 0.6165 || 10iter: 5.2325 sec. || 本イテレーションの正解率：0.75\n",
            "イテレーション 40 || Loss: 0.5764 || 10iter: 5.2666 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 50 || Loss: 0.6147 || 10iter: 5.3170 sec. || 本イテレーションの正解率：0.6875\n",
            "イテレーション 60 || Loss: 0.5917 || 10iter: 5.3466 sec. || 本イテレーションの正解率：0.71875\n",
            "イテレーション 70 || Loss: 0.5331 || 10iter: 5.4114 sec. || 本イテレーションの正解率：0.75\n",
            "イテレーション 80 || Loss: 0.4599 || 10iter: 5.4321 sec. || 本イテレーションの正解率：0.78125\n",
            "イテレーション 90 || Loss: 0.3984 || 10iter: 5.4794 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 100 || Loss: 0.3283 || 10iter: 5.5143 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 110 || Loss: 0.4501 || 10iter: 5.5501 sec. || 本イテレーションの正解率：0.75\n",
            "イテレーション 120 || Loss: 0.1814 || 10iter: 5.5962 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 130 || Loss: 0.3434 || 10iter: 5.6578 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 140 || Loss: 0.5984 || 10iter: 5.7421 sec. || 本イテレーションの正解率：0.78125\n",
            "イテレーション 150 || Loss: 0.2487 || 10iter: 5.8303 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 160 || Loss: 0.2182 || 10iter: 5.9244 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 170 || Loss: 0.4020 || 10iter: 6.0093 sec. || 本イテレーションの正解率：0.78125\n",
            "イテレーション 180 || Loss: 0.2863 || 10iter: 6.0011 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 190 || Loss: 0.2791 || 10iter: 5.9278 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 200 || Loss: 0.2780 || 10iter: 5.8753 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 210 || Loss: 0.2336 || 10iter: 5.8053 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 220 || Loss: 0.3260 || 10iter: 5.7788 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 230 || Loss: 0.2796 || 10iter: 5.7554 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 240 || Loss: 0.2625 || 10iter: 5.7567 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 250 || Loss: 0.2508 || 10iter: 5.7468 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 260 || Loss: 0.2650 || 10iter: 5.7506 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 270 || Loss: 0.2647 || 10iter: 5.7575 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 280 || Loss: 0.3322 || 10iter: 5.7789 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 290 || Loss: 0.5590 || 10iter: 5.8112 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 300 || Loss: 0.4510 || 10iter: 5.8299 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 310 || Loss: 0.3322 || 10iter: 5.8476 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 320 || Loss: 0.2838 || 10iter: 5.8713 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 330 || Loss: 0.4210 || 10iter: 5.8607 sec. || 本イテレーションの正解率：0.78125\n",
            "イテレーション 340 || Loss: 0.3397 || 10iter: 5.8431 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 350 || Loss: 0.2284 || 10iter: 5.8387 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 360 || Loss: 0.2426 || 10iter: 5.8289 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 370 || Loss: 0.2217 || 10iter: 5.8157 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 380 || Loss: 0.0946 || 10iter: 5.8165 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 390 || Loss: 0.1369 || 10iter: 5.8121 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 400 || Loss: 0.3711 || 10iter: 5.8095 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 410 || Loss: 0.3461 || 10iter: 5.8032 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 420 || Loss: 0.2846 || 10iter: 5.8277 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 430 || Loss: 0.2128 || 10iter: 5.8167 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 440 || Loss: 0.3678 || 10iter: 5.8152 sec. || 本イテレーションの正解率：0.75\n",
            "イテレーション 450 || Loss: 0.4276 || 10iter: 5.8185 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 460 || Loss: 0.1380 || 10iter: 5.8243 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 470 || Loss: 0.3850 || 10iter: 5.8111 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 480 || Loss: 0.1258 || 10iter: 5.8128 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 490 || Loss: 0.2756 || 10iter: 5.8161 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 500 || Loss: 0.2273 || 10iter: 5.8339 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 510 || Loss: 0.4472 || 10iter: 5.8489 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 520 || Loss: 0.1559 || 10iter: 5.8496 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 530 || Loss: 0.1993 || 10iter: 5.8685 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 540 || Loss: 0.1745 || 10iter: 5.8604 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 550 || Loss: 0.2160 || 10iter: 5.8616 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 560 || Loss: 0.3923 || 10iter: 5.8483 sec. || 本イテレーションの正解率：0.78125\n",
            "イテレーション 570 || Loss: 0.2404 || 10iter: 5.8525 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 580 || Loss: 0.3726 || 10iter: 5.8518 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 590 || Loss: 0.2572 || 10iter: 5.8648 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 600 || Loss: 0.4863 || 10iter: 5.8553 sec. || 本イテレーションの正解率：0.75\n",
            "イテレーション 610 || Loss: 0.3084 || 10iter: 5.8482 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 620 || Loss: 0.2230 || 10iter: 5.8330 sec. || 本イテレーションの正解率：0.875\n",
            "Epoch 1/2 | train |  Loss: 0.3446 Acc: 0.8456\n",
            "Epoch 1/2 |  val  |  Loss: 0.2636 Acc: 0.8964\n",
            "イテレーション 10 || Loss: 0.2588 || 10iter: 5.8708 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 20 || Loss: 0.2330 || 10iter: 5.8254 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 30 || Loss: 0.2294 || 10iter: 5.8207 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 40 || Loss: 0.2188 || 10iter: 5.8001 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 50 || Loss: 0.1398 || 10iter: 5.8091 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 60 || Loss: 0.1415 || 10iter: 5.8094 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 70 || Loss: 0.2485 || 10iter: 5.8239 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 80 || Loss: 0.1988 || 10iter: 5.8308 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 90 || Loss: 0.1699 || 10iter: 5.8248 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 100 || Loss: 0.2757 || 10iter: 5.8479 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 110 || Loss: 0.2142 || 10iter: 5.8623 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 120 || Loss: 0.2618 || 10iter: 5.8814 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 130 || Loss: 0.2514 || 10iter: 5.8722 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 140 || Loss: 0.1448 || 10iter: 5.8593 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 150 || Loss: 0.2344 || 10iter: 5.8572 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 160 || Loss: 0.1668 || 10iter: 5.8464 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 170 || Loss: 0.4270 || 10iter: 5.8460 sec. || 本イテレーションの正解率：0.78125\n",
            "イテレーション 180 || Loss: 0.4282 || 10iter: 5.8257 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 190 || Loss: 0.1730 || 10iter: 5.8191 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 200 || Loss: 0.3576 || 10iter: 5.8212 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 210 || Loss: 0.3757 || 10iter: 5.8019 sec. || 本イテレーションの正解率：0.8125\n",
            "イテレーション 220 || Loss: 0.2189 || 10iter: 5.8143 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 230 || Loss: 0.1253 || 10iter: 5.8185 sec. || 本イテレーションの正解率：1.0\n",
            "イテレーション 240 || Loss: 0.2042 || 10iter: 5.8141 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 250 || Loss: 0.3480 || 10iter: 5.8266 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 260 || Loss: 0.1883 || 10iter: 5.8229 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 270 || Loss: 0.3191 || 10iter: 5.8234 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 280 || Loss: 0.1957 || 10iter: 5.8263 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 290 || Loss: 0.0952 || 10iter: 5.8298 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 300 || Loss: 0.1283 || 10iter: 5.8267 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 310 || Loss: 0.1955 || 10iter: 5.8309 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 320 || Loss: 0.1029 || 10iter: 5.8337 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 330 || Loss: 0.3135 || 10iter: 5.8407 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 340 || Loss: 0.1933 || 10iter: 5.8376 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 350 || Loss: 0.1242 || 10iter: 5.8512 sec. || 本イテレーションの正解率：0.96875\n",
            "イテレーション 360 || Loss: 0.3508 || 10iter: 5.8481 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 370 || Loss: 0.2486 || 10iter: 5.8303 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 380 || Loss: 0.1795 || 10iter: 5.8268 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 390 || Loss: 0.4962 || 10iter: 5.8266 sec. || 本イテレーションの正解率：0.78125\n",
            "イテレーション 400 || Loss: 0.3694 || 10iter: 5.8036 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 410 || Loss: 0.3529 || 10iter: 5.8107 sec. || 本イテレーションの正解率：0.84375\n",
            "イテレーション 420 || Loss: 0.2333 || 10iter: 5.8081 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 430 || Loss: 0.3824 || 10iter: 5.8232 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 440 || Loss: 0.1444 || 10iter: 5.8189 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 450 || Loss: 0.3427 || 10iter: 5.8366 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 460 || Loss: 0.3549 || 10iter: 5.8575 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 470 || Loss: 0.1709 || 10iter: 5.8672 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 480 || Loss: 0.2838 || 10iter: 5.8571 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 490 || Loss: 0.1973 || 10iter: 5.8463 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 500 || Loss: 0.3566 || 10iter: 5.8428 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 510 || Loss: 0.2112 || 10iter: 5.8403 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 520 || Loss: 0.1578 || 10iter: 5.8487 sec. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 530 || Loss: 0.1418 || 10iter: 5.8442 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 540 || Loss: 0.3021 || 10iter: 5.8443 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 550 || Loss: 0.2946 || 10iter: 5.8227 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 560 || Loss: 0.2303 || 10iter: 5.8326 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 570 || Loss: 0.2707 || 10iter: 5.8348 sec. || 本イテレーションの正解率：0.875\n",
            "イテレーション 580 || Loss: 0.3451 || 10iter: 5.8187 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 590 || Loss: 0.3739 || 10iter: 5.8132 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 600 || Loss: 0.1473 || 10iter: 5.8236 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 610 || Loss: 0.2870 || 10iter: 5.8180 sec. || 本イテレーションの正解率：0.90625\n",
            "イテレーション 620 || Loss: 0.3297 || 10iter: 5.8298 sec. || 本イテレーションの正解率：0.84375\n",
            "Epoch 2/2 | train |  Loss: 0.2595 Acc: 0.8940\n",
            "Epoch 2/2 |  val  |  Loss: 0.2459 Acc: 0.9038\n"
          ]
        }
      ],
      "source": [
        "# 学習・検証を実行する。 \n",
        "# 8 minutes per epoch, 16 minutes in total on GC with GPU\n",
        "\n",
        "num_epochs = 2\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BWTS_gSOT5tv"
      },
      "outputs": [],
      "source": [
        "# 学習したネットワークパラメータを保存します\n",
        "save_path = './weights/bert_fine_tuning_IMDb.pth'\n",
        "torch.save(net_trained.state_dict(), save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "36JYaufeT5tv",
        "outputId": "f3fff6f2-aa4e-4e82-ef93-7b62d8639a85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [07:14<00:00,  1.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "テストデータ25000個での正解率：0.9056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# テストデータでの正解率を求める\n",
        "# it takes 8 minutes or so (GC with GPU)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()   # モデルを検証モードに\n",
        "net_trained.to(device)  # GPUが使えるならGPUへ送る\n",
        "\n",
        "# epochの正解数を記録する変数\n",
        "epoch_corrects = 0\n",
        "\n",
        "for batch in tqdm(test_dl):  # testデータのDataLoader\n",
        "    # batchはTextとLableの辞書オブジェクト\n",
        "    # GPUが使えるならGPUにデータを送る\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = batch.Text[0].to(device)  # 文章\n",
        "    labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "    # 順伝搬（forward）計算\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # BertForIMDbに入力\n",
        "        outputs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
        "                              output_all_encoded_layers=False, attention_show_flg=False)\n",
        "\n",
        "        loss = criterion(outputs, labels)  # 損失を計算\n",
        "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "        epoch_corrects += torch.sum(preds == labels.data)  # 正解数の合計を更新\n",
        "\n",
        "# 正解率\n",
        "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
        "\n",
        "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dl.dataset), epoch_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "168YPhmvT5tv"
      },
      "source": [
        "# Attentionの可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuWBCGxKT5tv"
      },
      "outputs": [],
      "source": [
        "# batch_sizeを64にしたテストデータでDataLoaderを作成\n",
        "# https://github.com/YutaroOgawa/pytorch_advanced/issues/148\n",
        "\n",
        "batch_size = 64\n",
        "test_dl = torchtext.data.Iterator(\n",
        "    test_ds, batch_size=batch_size, train=False, sort=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qdf04xCTT5tv"
      },
      "outputs": [],
      "source": [
        "# BertForIMDbで処理\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(test_dl))\n",
        "\n",
        "# GPUが使えるならGPUにデータを送る\n",
        "inputs = batch.Text[0].to(device)  # 文章\n",
        "labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "outputs, attention_probs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
        "                                       output_all_encoded_layers=False, attention_show_flg=True)\n",
        "\n",
        "_, preds = torch.max(outputs, 1)  # ラベルを予測\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svGK4qb8T5tw"
      },
      "outputs": [],
      "source": [
        "# HTMLを作成する関数を実装\n",
        "\n",
        "\n",
        "def highlight(word, attn):\n",
        "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
        "\n",
        "    html_color = '#%02X%02X%02X' % (\n",
        "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
        "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
        "\n",
        "\n",
        "def mk_html(index, batch, preds, normlized_weights, TEXT):\n",
        "    \"HTMLデータを作成する\"\n",
        "\n",
        "    # indexの結果を抽出\n",
        "    sentence = batch.Text[0][index]  # 文章\n",
        "    label = batch.Label[index]  # ラベル\n",
        "    pred = preds[index]  # 予測\n",
        "\n",
        "    # ラベルと予測結果を文字に置き換え\n",
        "    if label == 0:\n",
        "        label_str = \"Negative\"\n",
        "    else:\n",
        "        label_str = \"Positive\"\n",
        "\n",
        "    if pred == 0:\n",
        "        pred_str = \"Negative\"\n",
        "    else:\n",
        "        pred_str = \"Positive\"\n",
        "\n",
        "    # 表示用のHTMLを作成する\n",
        "    html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(label_str, pred_str)\n",
        "\n",
        "    # Self-Attentionの重みを可視化。Multi-Headが12個なので、12種類のアテンションが存在\n",
        "    for i in range(12):\n",
        "\n",
        "        # indexのAttentionを抽出と規格化\n",
        "        # 0単語目[CLS]の、i番目のMulti-Head Attentionを取り出す\n",
        "        # indexはミニバッチの何個目のデータかをしめす\n",
        "        attens = normlized_weights[index, i, 0, :]\n",
        "        attens /= attens.max()\n",
        "\n",
        "        html += '[BERTのAttentionを可視化_' + str(i+1) + ']<br>'\n",
        "        for word, attn in zip(sentence, attens):\n",
        "\n",
        "            # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
        "            if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "                break\n",
        "\n",
        "            # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
        "            html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
        "                [word.numpy().tolist()])[0], attn)\n",
        "        html += \"<br><br>\"\n",
        "\n",
        "    # 12種類のAttentionの平均を求める。最大値で規格化\n",
        "    all_attens = attens*0  # all_attensという変数を作成する\n",
        "    for i in range(12):\n",
        "        attens += normlized_weights[index, i, 0, :]\n",
        "    attens /= attens.max()\n",
        "\n",
        "    html += '[BERTのAttentionを可視化_ALL]<br>'\n",
        "    for word, attn in zip(sentence, attens):\n",
        "\n",
        "        # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
        "        if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "            break\n",
        "\n",
        "        # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
        "        html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
        "            [word.numpy().tolist()])[0], attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    return html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_zmplqST5tw"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "index = 3  # 出力させたいデータ\n",
        "html_output = mk_html(index, batch, preds, attention_probs, TEXT)  # HTML作成\n",
        "HTML(html_output)  # HTML形式で出力\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvve5kcOT5tw"
      },
      "outputs": [],
      "source": [
        "index = 61  # 出力させたいデータ\n",
        "html_output = mk_html(index, batch, preds, attention_probs, TEXT)  # HTML作成\n",
        "HTML(html_output)  # HTML形式で出力\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_IHTT6VT5tw"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nNYDnDTcNYm"
      },
      "source": [
        "---\n",
        "Revised by KAMEDA, Yoshinari at University of Tsukuba for lecture purpose.  \n",
        "Original: https://github.com/YutaroOgawa/pytorch_advanced\n",
        "\n",
        "2022/08/08.  \n",
        "2021/08/05. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GC8-4_bert_IMDb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}