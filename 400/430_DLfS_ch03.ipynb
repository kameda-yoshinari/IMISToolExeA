{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "430-DLfS-ch03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMyZb9cXs+VZBcmX1zwGZz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameda-yoshinari/IMISToolExeA2022/blob/main/400/430_DLfS_ch03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IunZb1eqUdur"
      },
      "source": [
        "# ゼロから作るDeep Learning ch03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoB0f6lbUZP1"
      },
      "source": [
        "!echo \"Change to the JST notation.\"\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Japan /etc/localtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgYXd3C3UhdE"
      },
      "source": [
        "!echo \"Start mounting your Google Drive.\"\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "!echo \"Make a working folder and move to there.\"\n",
        "%cd /content/drive/My\\ Drive/\n",
        "%cd IMIS_Tool-A/Work400/deep-learning-from-scratch-master\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk85QIoEUjR-"
      },
      "source": [
        "%cd ch03"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMC7qkSCUlvv"
      },
      "source": [
        "---\n",
        "# 3.2.3 step_function.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGx16RGVVECy"
      },
      "source": [
        "!python step_function.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTacF15kVSS_"
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "def step_function(x):\n",
        "    return np.array(x > 0, dtype=np.int)\n",
        "\n",
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "Y = step_function(X)\n",
        "plt.plot(X, Y)\n",
        "plt.ylim(-0.1, 1.1)  # 図で描画するy軸の範囲を指定\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paV_oUTRVaFb"
      },
      "source": [
        "# 3.2.4 sigmoid.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnlFjr1_VhqV"
      },
      "source": [
        "!python sigmoid.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVw2WIMwVlkA"
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))    \n",
        "\n",
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "Y = sigmoid(X)\n",
        "plt.plot(X, Y)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I9KMdQvV3qS"
      },
      "source": [
        "# 3.2.5 sig_step_compare.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DqvE6EMV6k3"
      },
      "source": [
        "!python sig_step_compare.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGNIgAd5V9pI"
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))    \n",
        "\n",
        "\n",
        "def step_function(x):\n",
        "    return np.array(x > 0, dtype=np.int)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y1 = sigmoid(x)\n",
        "y2 = step_function(x)\n",
        "\n",
        "plt.plot(x, y1)\n",
        "plt.plot(x, y2, 'k--')\n",
        "plt.ylim(-0.1, 1.1) #図で描画するy軸の範囲を指定\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpUmAY71X_Hc"
      },
      "source": [
        "# 3.2.7 relu.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pn57CYnYC-8"
      },
      "source": [
        "!python relu.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20U0ZCgbYF_i"
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = relu(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-1.0, 5.5)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbfFwpdUhrBz"
      },
      "source": [
        "# 3.6.1 mnist.py\n",
        "\n",
        "Mnist dataset on http://yann.lecun.com/exdb/mnist/ has gone.  \n",
        "So just take the mirror provided by PyTorch (on AWS).  \n",
        "=>See the url_base at line 14 in (new) mnist.py\n",
        "\n",
        "**You should modify the dataset/mnist.py as it is **\n",
        "\n",
        "Ref: \n",
        "https://stackoverflow.com/questions/66577151/http-error-when-trying-to-download-mnist-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_idnT9vh5rE"
      },
      "source": [
        "%%writefile ../dataset/mnist.py\n",
        "# New mnist.py\n",
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "url_base = 'https://ossci-datasets.s3.amazonaws.com/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "dataset_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\"}\n",
        "    request = urllib.request.Request(url_base+file_name, headers=headers)\n",
        "    response = urllib.request.urlopen(request).read()\n",
        "    with open(file_path, mode='wb') as f:\n",
        "        f.write(response)\n",
        "    print(\"Done\")\n",
        "\n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "\n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "\n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "\n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "\n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])\n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "\n",
        "    return T\n",
        "\n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"MNISTデータセットの読み込み\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 画像のピクセル値を0.0~1.0に正規化する\n",
        "    one_hot_label :\n",
        "        one_hot_labelがTrueの場合、ラベルはone-hot配列として返す\n",
        "        one-hot配列とは、たとえば[0,0,1,0,0,0,0,0,0,0]のような配列\n",
        "    flatten : 画像を一次元配列に平にするかどうか\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    (訓練画像, 訓練ラベル), (テスト画像, テストラベル)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "\n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "\n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "\n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
        "\n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_mnist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT09lq5rjXr8"
      },
      "source": [
        "!cat ../dataset/mnist.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qya9EaYeKUh"
      },
      "source": [
        "# 3.6.1 mnist_show.py\n",
        "\n",
        "Since the PIL is not supported on google colaboratory for image display, you should use matplotlib (same as lena.png in 1.6.3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LNcch3TeNSV"
      },
      "source": [
        "!python mnist_show.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Maw00vqieR4h"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from PIL import Image\n",
        "from matplotlib.image import imread # added\n",
        "\n",
        "\n",
        "def img_show(img):\n",
        "    pil_img = Image.fromarray(np.uint8(img))\n",
        "    pil_img.show() # this does not work ...\n",
        "    plt.imshow(pil_img) # added\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "print(label)  # 5\n",
        "\n",
        "print(img.shape)  # (784,)\n",
        "img = img.reshape(28, 28)  # 形状を元の画像サイズに変形\n",
        "print(img.shape)  # (28, 28)\n",
        "\n",
        "img_show(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcwVACMVZE9e"
      },
      "source": [
        "# 3.6.2 neuralnet_mnist.py\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u72R_3t0ZJil"
      },
      "source": [
        "!python neuralnet_mnist.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8IZ8dOQZZfw"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import pickle\n",
        "from dataset.mnist import load_mnist\n",
        "from common.functions import sigmoid, softmax\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "    return x_test, t_test\n",
        "\n",
        "\n",
        "def init_network():\n",
        "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
        "        network = pickle.load(f)\n",
        "    return network\n",
        "\n",
        "\n",
        "def predict(network, x):\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, W3) + b3\n",
        "    y = softmax(a3)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "x, t = get_data()\n",
        "network = init_network()\n",
        "accuracy_cnt = 0\n",
        "for i in range(len(x)):\n",
        "    y = predict(network, x[i])\n",
        "    p= np.argmax(y) # 最も確率の高い要素のインデックスを取得\n",
        "    if p == t[i]:\n",
        "        accuracy_cnt += 1\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IazwoMexfzHm"
      },
      "source": [
        "# 3.6.3 neuralnet_mnist_batch.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zryo4EHf5fQ"
      },
      "source": [
        "!python neuralnet_mnist_batch.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwLIyCI6f-_O"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import pickle\n",
        "from dataset.mnist import load_mnist\n",
        "from common.functions import sigmoid, softmax\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "    return x_test, t_test\n",
        "\n",
        "\n",
        "def init_network():\n",
        "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
        "        network = pickle.load(f)\n",
        "    return network\n",
        "\n",
        "\n",
        "def predict(network, x):\n",
        "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    a1 = np.dot(x, w1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, w2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, w3) + b3\n",
        "    y = softmax(a3)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "batch_size = 100 # バッチの数\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size):\n",
        "    x_batch = x[i:i+batch_size]\n",
        "    y_batch = predict(network, x_batch)\n",
        "    p = np.argmax(y_batch, axis=1)\n",
        "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B_mM3VXWG1j"
      },
      "source": [
        "---\n",
        "Tools and Practices for Intelligent Interaction Systems A  \n",
        "Master's and Docotal programs in intelligent and mechanical interaction systems, University of Tsukuba, Japan.  \n",
        "KAMEDA Yoshinari, SHIBUYA Takeshi  \n",
        "\n",
        "知能システムツール演習a  \n",
        "知能機能システム学位プログラム (筑波大学大学院)  \n",
        "担当：亀田能成，澁谷長史  \n",
        "\n",
        "2022/08/01.  \n",
        "2021/07/26.  \n",
        "\n"
      ]
    }
  ]
}